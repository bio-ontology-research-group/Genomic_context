{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c622ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 258.74 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.available / (1024.0 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "abdd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4afee737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d69a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"WordLevel_tokenizer_trained_InterPro.json\"\n",
    "tokenizer = tokenizer.from_file(tokenizer_path)\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0bef36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544998"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "242995ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2966, 754, 2545, 196, 9231, 2817, 7418, 2526, 2]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode(\"WP_265490204 WP_206642677 WP_053312998 WP_251959347 WP_000076573 WP_227526754 WP_218401808 WP_106925592\")\n",
    "test.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a5c8709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIT_IP.tsv\n",
      "CRISPR_IP.tsv\n",
      "BREX_IP.tsv\n",
      "DISARM_IP.tsv\n",
      "AbiH_IP.tsv\n",
      "Kiwa_IP.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "defense_ips = []\n",
    "directory = \"/home/toibazd/Defense_InterPros/\"\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    file_path = os.path.join(directory, file)\n",
    "    with open(file_path, 'r', newline='') as infile:\n",
    "        reader = csv.reader(infile, delimiter = \"\\t\")\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            ip = row[0]\n",
    "            defense_ips.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "679dec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defense IPs number:  120\n"
     ]
    }
   ],
   "source": [
    "print(\"Defense IPs number: \", len(defense_ips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07ba9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020214557647705078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bd8db303fb4f5e89bf7090c5058401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data_dict = defaultdict(list)\n",
    "\n",
    "with open(\"/home/toibazd/Prot2IP.tsv\", \"r\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter = \"\\t\")\n",
    "    for row in tqdm(reader):\n",
    "        key = row[0].split(\"prot_\")[1].split(\".\")[0]\n",
    "        iprs = eval(row[1])\n",
    "\n",
    "        # Save only if there are filtered InterPro IDs\n",
    "        for ip in iprs:\n",
    "            if ip in defense_ips:\n",
    "                data_dict[key].append(ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "334d007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_defense = set()\n",
    "\n",
    "# Iterate through each value list in the dictionary and add its elements to the set\n",
    "for value_list in data_dict.values():\n",
    "    unique_defense.update(value_list)\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "unique_defense = list(unique_defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88b651fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "83f471e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "enc = MultiLabelBinarizer()\n",
    "one_hot_encoded = enc.fit_transform(data_dict.values())\n",
    "one_hot_encoded_dict = {key: value for key, value in zip(data_dict.keys(), one_hot_encoded)}\n",
    "\n",
    "print(len(one_hot_encoded_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7464990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 83)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a51e75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# directory = '/ibex/user/toibazd/InterPro_annotated_genomes/'\n",
    "# one_hot_encoded_sentences = {}\n",
    "\n",
    "# sentence_length = 40\n",
    "# sentences_per_IP = 100\n",
    "\n",
    "# # Set random seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "# # Randomly choose 1000 files with seed 42\n",
    "# selected_files = os.listdir(directory)\n",
    "\n",
    "\n",
    "# # Define a function to process a file\n",
    "# def process_file(filename, IP):\n",
    "#     sentences = []\n",
    "\n",
    "#     filepath = os.path.join(directory, filename)\n",
    "\n",
    "#     with open(filepath, 'r') as file:\n",
    "#         content = file.read()\n",
    "#         words = content.strip().split()\n",
    "\n",
    "#         # Check if the key is in the file\n",
    "#         for i in range(19, len(words)-20):\n",
    "#             if IP in data_dict[words[i]]:\n",
    "#                 if len(words) - i >= 21:\n",
    "#                     sentence = \" \".join(words[i - 19:i + sentence_length - 19])\n",
    "#                     sentences.append(sentence)\n",
    "#     return sentences\n",
    "\n",
    "\n",
    "# # Iterate over keys\n",
    "# for IP in tqdm(unique_defense):\n",
    "#     one_hot_encoded_sentences[IP] = []\n",
    "#     sentences_count = 0\n",
    "\n",
    "#     # Use ThreadPoolExecutor for concurrent processing\n",
    "#     with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "#         futures = [executor.submit(process_file, filename, IP) for filename in selected_files]\n",
    "#         for future in futures:\n",
    "#             sentences = future.result()\n",
    "#             one_hot_encoded_sentences[IP].extend(sentences)\n",
    "#             sentences_count += len(sentences)\n",
    "#             if sentences_count >= sentences_per_IP:\n",
    "#                 break\n",
    "\n",
    "#     # Break if the required number of sentences per key is reached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abea8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, values in one_hot_encoded_sentences.items():\n",
    "#     print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a55b4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('BERT_sanity_check_defense_DNN_senteces.json', 'w') as f:\n",
    "#     json.dump(one_hot_encoded_sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeeb70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('BERT_sanity_check_defense_DNN_senteces.json', \"r\") as f:\n",
    "    one_hot_encoded_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b1149a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPR013381 100\n",
      "IPR030955 19\n",
      "IPR013487 18\n",
      "IPR028629 106\n",
      "IPR047679 100\n",
      "IPR013410 51\n",
      "IPR048067 71\n",
      "IPR010154 100\n",
      "IPR047721 100\n",
      "IPR047939 100\n",
      "IPR010147 100\n",
      "IPR010144 100\n",
      "IPR017576 19\n",
      "IPR013421 59\n",
      "IPR013489 100\n",
      "IPR017575 33\n",
      "IPR010160 14\n",
      "IPR027620 25\n",
      "IPR019089 77\n",
      "IPR014174 100\n",
      "IPR021124 100\n",
      "IPR010152 100\n",
      "IPR010172 48\n",
      "IPR049832 42\n",
      "IPR005537 101\n",
      "IPR013413 57\n",
      "IPR010180 100\n",
      "IPR049889 36\n",
      "IPR019199 100\n",
      "IPR013414 100\n",
      "IPR010156 100\n",
      "IPR013403 73\n",
      "IPR013408 100\n",
      "IPR002729 102\n",
      "IPR013415 28\n",
      "IPR017574 56\n",
      "IPR013419 65\n",
      "IPR010179 100\n",
      "IPR047583 26\n",
      "IPR027616 34\n",
      "IPR049794 17\n",
      "IPR017589 33\n",
      "IPR010149 100\n",
      "IPR013490 19\n",
      "IPR019857 100\n",
      "IPR013492 100\n",
      "IPR013396 100\n",
      "IPR019858 100\n",
      "IPR021127 100\n",
      "IPR006482 100\n",
      "IPR033641 100\n",
      "IPR032359 100\n",
      "IPR013418 100\n",
      "IPR010148 101\n",
      "IPR019855 100\n",
      "IPR019851 100\n",
      "IPR013444 20\n",
      "IPR013343 100\n",
      "IPR013395 100\n",
      "IPR013398 100\n",
      "IPR031820 84\n",
      "IPR013397 100\n",
      "IPR019504 100\n",
      "IPR013412 100\n",
      "IPR010155 100\n",
      "IPR013382 100\n",
      "IPR014858 100\n",
      "IPR019092 57\n",
      "IPR023843 69\n",
      "IPR013399 100\n",
      "IPR021228 100\n",
      "IPR005510 100\n",
      "IPR010146 100\n",
      "IPR025935 100\n",
      "IPR013407 34\n",
      "IPR023844 49\n",
      "IPR013337 100\n",
      "IPR010173 100\n",
      "IPR049758 33\n",
      "IPR016581 27\n",
      "IPR027617 35\n",
      "IPR019117 16\n",
      "IPR019856 100\n"
     ]
    }
   ],
   "source": [
    "for key, value in one_hot_encoded_sentences.items():\n",
    "    print(key, end=\" \")\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "deeb72f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_sentences = {key: value for key, value in one_hot_encoded_sentences.items() if value}\n",
    "len(one_hot_encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2219cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = one_hot_encoded_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea88291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6354"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c1c4fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6354\n"
     ]
    }
   ],
   "source": [
    "count= 0\n",
    "for string in matching_string:\n",
    "    words = string.split(\" \")\n",
    "    if not words[19] in data_dict.keys():\n",
    "        print(\"False\")\n",
    "    else:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b43fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(544998, 256, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (token_type_embeddings): Embedding(2, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): None\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Check if CUDA is available and choose device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"/home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final\"\n",
    "\n",
    "model = BertModel.from_pretrained(model_path).cuda()\n",
    "model.pooler = None\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "978dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_encoded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c35dd100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01699376106262207,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c393d02b812b43fd89e0b14891cec7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128 # Define your batch size\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "\n",
    "    # Convert lists to tensors and move to device\n",
    "    input_ids = torch.tensor(input_ids_list).cuda()\n",
    "    attention_mask = torch.tensor(attention_mask_list).cuda()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]  # Extract the 20th token's hidden state\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        labels.append(one_hot_encoded_dict[indicator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7cad879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83,)\n"
     ]
    }
   ],
   "source": [
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    \n",
    "    neg_counts = [len(embeddings)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "      pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)\n",
    "class_counts = np.array(labels).sum(axis=0)\n",
    "print(class_counts.shape)\n",
    "pos_weights = calculate_pos_weights(class_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1476691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  9.1667,  2.1667,  3.6667, 10.3333, 10.3333,  5.3333,  6.3333,\n",
       "        10.3333, 10.3333,  4.3333,  9.0000, 10.3333, 75.3333, 19.3333,  7.8333,\n",
       "        10.3333, 10.3333, 10.1667,  6.8333, 10.3333,  8.3333, 10.3333, 10.3333,\n",
       "        10.3333, 10.3333, 10.3333, 14.3333, 30.8333, 10.3333, 19.6667,  7.1667,\n",
       "         9.0000,  5.0000, 37.5000,  7.1667, 15.5000, 17.6667, 52.6667, 58.5000,\n",
       "        10.3333, 50.1667, 10.3333, 10.3333, 10.3333, 24.3333, 18.6667, 31.8333,\n",
       "        55.5000, 31.8333, 13.5000,  9.0000, 66.0000,  5.0000, 10.3333,  4.6667,\n",
       "         9.6667, 10.0000,  9.6667,  9.8333,  2.3333,  7.6667, 10.3333, 15.1667,\n",
       "        20.1667, 10.3333, 30.8333, 30.0000, 42.1667,  9.6667, 55.5000, 12.3333,\n",
       "        10.3333,  4.8333, 40.5000, 10.3333, 10.3333, 10.3333, 14.6667, 31.8333,\n",
       "        62.0000, 25.0000, 29.1667])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights = pos_weights / torch.min(pos_weights)\n",
    "\n",
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1fc1f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "combined = list(zip(embeddings, labels))\n",
    "random.shuffle(combined)\n",
    "embeddings, labels = zip(*combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7184dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7403eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01665043830871582,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6354,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9357edd2e7cb47668ee9187050c20b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "random_embeddings = []\n",
    "for embedding in tqdm(embeddings):\n",
    "    random_embedding = torch.randn_like(embedding)  # Generate random tensor with same shape as 'embedding'\n",
    "    random_embeddings.append(random_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f832c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classification_V0(nn.Module):\n",
    "    def __init__(self, input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob):\n",
    "        super(Classification_V0, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, first_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_hidden, second_hidden)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_hidden, last_hidden)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(last_hidden, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 256\n",
    "first_hidden = 128\n",
    "second_hidden = 64\n",
    "last_hidden = 32\n",
    "output_dim = 83\n",
    "dropout_prob = 0.25\n",
    "\n",
    "clf_model = Classification_V0(input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7d9abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "batch_size = 128\n",
    "def data_generator(embeddings, labels, batch_size):\n",
    "    num_samples = len(embeddings)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_embeddings = embeddings[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        yield batch_embeddings, batch_labels\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(clf_model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad1b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021236658096313477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3691508983867815\n",
      "Epoch 2/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02093338966369629,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3647749711403803\n",
      "Epoch 3/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020708799362182617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3587685603933362\n",
      "Epoch 4/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020678997039794922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3478299778213958\n",
      "Epoch 5/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020808696746826172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3285910654713382\n",
      "Epoch 6/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020627498626708984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2957802719389975\n",
      "Epoch 7/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020656824111938477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2637833885550687\n",
      "Epoch 8/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02067089080810547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2297554196221745\n",
      "Epoch 9/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020608901977539062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1998020997015906\n",
      "Epoch 10/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020856380462646484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1661999840236588\n",
      "Epoch 11/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02065134048461914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1384513357881108\n",
      "Epoch 12/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020607471466064453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1320254596329575\n",
      "Epoch 13/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02069568634033203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1288434185620033\n",
      "Epoch 14/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02068352699279785,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1199019794986427\n",
      "Epoch 15/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020635604858398438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.122611780980116\n",
      "Epoch 16/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020891189575195312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1147751200300438\n",
      "Epoch 17/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02064824104309082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1144919126784985\n",
      "Epoch 18/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02078843116760254,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1071336822461737\n",
      "Epoch 19/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020706653594970703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1038204669802303\n",
      "Epoch 20/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020656347274780273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.108950743706751\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 20\n",
    "epoch_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    \n",
    "    # Initialize data generator\n",
    "    generator = data_generator(random_embeddings, labels, batch_size)\n",
    "    train_loss = 0\n",
    "    # Iterate over batches\n",
    "    for batch_embeddings, batch_labels in tqdm(generator, desc=\"Training Batches\", leave=False):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert data to tensors\n",
    "\n",
    "        batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_labels_tensor = torch.tensor(batch_labels, dtype = torch.float32)\n",
    "        outputs = clf_model(batch_embeddings_tensor)\n",
    "        loss = criterion(outputs, batch_labels_tensor)\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    epoch_loss.append(train_loss/(len(embeddings)/batch_size))\n",
    "    print(train_loss/(len(embeddings)/batch_size))\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ac44af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/ibex/user/toibazd/InterPro_annotated_genomes_for_testing/'\n",
    "# one_hot_encoded_sentences_2 = {}\n",
    "\n",
    "# sentence_length = 40\n",
    "# sentence_per_IP = 50\n",
    "# selected_files = os.listdir(directory)\n",
    "\n",
    "# total_sentences = sum(len(sentences) for sentences in one_hot_encoded_sentences.values())\n",
    "\n",
    "# # Iterate over keys\n",
    "# for IP in tqdm(unique_defense):\n",
    "#     one_hot_encoded_sentences_2[IP] = []\n",
    "#     sentences_count=0\n",
    "    \n",
    "#     # Iterate over selected files\n",
    "#     for filename in selected_files:\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "\n",
    "#         with open(filepath, 'r') as file:\n",
    "#             content = file.read()\n",
    "#             words = content.strip().split()\n",
    "\n",
    "#             # Check if the key is in the file\n",
    "#             for i in range(19, len(words)-20):\n",
    "#                 # Shuffle the indices of the words containing the key\n",
    "#                 if IP in data_dict[words[i]]:\n",
    "#                     if len(words) - i >= 21:\n",
    "#                         sentence = \" \".join(words[i - 19:i + sentence_length - 19])\n",
    "#                         one_hot_encoded_sentences_2[IP].append(sentence)\n",
    "#                         sentences_count += 1\n",
    "#                         if sentences_count>=sentence_per_IP:\n",
    "#                             break\n",
    "#         if sentences_count>=sentence_per_IP:\n",
    "#             break\n",
    "#     print(sentences_count)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7873eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in one_hot_encoded_sentences_2.items():\n",
    "#     print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e5a2eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('BERT_sanity_check_defense_DNN_senteces_testing.json', 'w') as f:\n",
    "#     json.dump(one_hot_encoded_sentences_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0aae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT_sanity_check_defense_DNN_senteces_testing.json', \"r\") as f:\n",
    "    test_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9ab316ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = {key: value for key, value in test_sentences.items() if value}\n",
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e3e213bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = test_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a93cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2659"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7d499e52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0168764591217041,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 21,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b732e8169c472e97200d8611ec9baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bertviz import model_view\n",
    "\n",
    "batch_size = 128\n",
    "# model.cuda()\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "    # Convert lists to tensors and move to device\n",
    "    try:\n",
    "        input_ids = torch.tensor(input_ids_list)\n",
    "    except:\n",
    "        for ins in input_ids_list:\n",
    "            if len(ins)!=42:\n",
    "                print(len(ins))\n",
    "                print(ins)\n",
    "    attention_mask = torch.tensor(attention_mask_list)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True, output_attentions = True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    attentions = outputs.attentions[-1]\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]  # Extract the 20th token's hidden state\n",
    "#     for i in range(len(batch_sentences)):\n",
    "#         if i < 20:\n",
    "#             att = []\n",
    "#             extracted_tensor = attentions[i, :, :, :]\n",
    "#             extracted_tensor = extracted_tensor.unsqueeze(0)\n",
    "#             print(extracted_tensor.shape)\n",
    "#             att.append(extracted_tensor)\n",
    "\n",
    "#             tokens = \"[CLS] \"+tokenizer.decode(input_ids_list[i])+\" [SEP]\"\n",
    "#             tokens = tokens.split(\" \")\n",
    "#             model_view(att, tokens)\n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        test_embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        test_labels.append(one_hot_encoded_dict[indicator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "00089282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WP_072018053 WP_072018053 WP_072018053 WP_072018053'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,12,12,12,12,\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b5d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e6194248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_V0(\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=32, out_features=83, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7122253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "test_random_embeddings = []\n",
    "for embedding in test_embeddings:\n",
    "    random_embedding = torch.randn_like(embedding)  # Generate random tensor with same shape as 'embedding'\n",
    "    test_random_embeddings.append(random_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d150c202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014863967895507812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluation Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = data_generator(test_random_embeddings, test_labels, batch_size)\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "for batch_embeddings, batch_labels in tqdm(generator, desc=\"Evaluation Batches\", leave=False):\n",
    "    batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "    batch_labels = np.array(batch_labels)\n",
    "    logits = clf_model(batch_embeddings_tensor)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "    thresholded_predictions = (predictions > 0.85).float()\n",
    "    all_predictions.append(thresholded_predictions.detach().numpy())\n",
    "    all_labels.append(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cd80f04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2eb88b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f0b4f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 83)\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fe31ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 83)\n"
     ]
    }
   ],
   "source": [
    "print(all_labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3a17e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate predictions and labels across all batches\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0fb58693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2659, 83)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "333465a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "cl_report = multilabel_confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Classification report:\")\n",
    "print(len(cl_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b75b6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2269    0]\n",
      " [ 390    0]]\n"
     ]
    }
   ],
   "source": [
    "print(cl_report[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6bb7d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toibazd/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/toibazd/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ecbf3a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        3., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0., 10.,  0.,  0.,  0.,  0.,  1., 15.,  0.,  0.,  0.,  6.,\n",
       "        8.,  1.,  1.,  2.,  0.,  0., 12., 10., 14.,  3.,  2.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,\n",
       "        0.,  1.,  0., 11.,  0.,  0.,  0.,  0.,  0., 16.,  0.,  0.,  0.,\n",
       "        0.,  3.,  2., 18.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "692d99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       390\n",
      "           1       0.00      0.00      0.00        58\n",
      "           2       0.00      0.00      0.00       190\n",
      "           3       0.00      0.00      0.00       105\n",
      "           4       0.00      0.00      0.00        50\n",
      "           5       0.00      0.00      0.00        50\n",
      "           6       0.00      0.00      0.00        88\n",
      "           7       0.00      0.00      0.00        75\n",
      "           8       0.00      0.00      0.00        50\n",
      "           9       0.00      0.00      0.00        50\n",
      "          10       0.00      0.00      0.00        94\n",
      "          11       0.00      0.00      0.00        58\n",
      "          12       0.00      0.00      0.00        50\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.00      0.00      0.00         9\n",
      "          15       0.00      0.00      0.00        66\n",
      "          16       0.00      0.00      0.00        50\n",
      "          17       0.00      0.00      0.00        21\n",
      "          18       0.00      0.00      0.00        27\n",
      "          19       0.00      0.00      0.00        61\n",
      "          20       0.00      0.00      0.00        50\n",
      "          21       0.00      0.00      0.00        58\n",
      "          22       0.00      0.00      0.00        50\n",
      "          23       0.00      0.00      0.00        50\n",
      "          24       0.00      0.00      0.00        50\n",
      "          25       0.00      0.00      0.00        50\n",
      "          26       0.00      0.00      0.00        50\n",
      "          27       0.00      0.00      0.00        13\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00        50\n",
      "          30       0.00      0.00      0.00        14\n",
      "          31       0.00      0.00      0.00        73\n",
      "          32       0.00      0.00      0.00        16\n",
      "          33       0.00      0.00      0.00        77\n",
      "          34       0.00      0.00      0.00         4\n",
      "          35       0.00      0.00      0.00        74\n",
      "          36       0.00      0.00      0.00         6\n",
      "          37       0.00      0.00      0.00        23\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        50\n",
      "          41       0.00      0.00      0.00         4\n",
      "          42       0.00      0.00      0.00        50\n",
      "          43       0.00      0.00      0.00        31\n",
      "          44       0.00      0.00      0.00        50\n",
      "          45       0.00      0.00      0.00        11\n",
      "          46       0.00      0.00      0.00        10\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.00      0.00      0.00        12\n",
      "          51       0.00      0.00      0.00        16\n",
      "          52       0.00      0.00      0.00         3\n",
      "          53       0.00      0.00      0.00       100\n",
      "          54       0.00      0.00      0.00        32\n",
      "          55       0.00      0.00      0.00       107\n",
      "          56       0.00      0.00      0.00        56\n",
      "          57       0.00      0.00      0.00        53\n",
      "          58       0.00      0.00      0.00        50\n",
      "          59       0.00      0.00      0.00        53\n",
      "          60       0.00      0.00      0.00       177\n",
      "          61       0.00      0.00      0.00        69\n",
      "          62       0.00      0.00      0.00        50\n",
      "          63       0.00      0.00      0.00        14\n",
      "          64       0.00      0.00      0.00        14\n",
      "          65       0.00      0.00      0.00        50\n",
      "          66       0.00      0.00      0.00        10\n",
      "          67       0.00      0.00      0.00        10\n",
      "          68       0.00      0.00      0.00         9\n",
      "          69       0.00      0.00      0.00        50\n",
      "          70       0.00      0.00      0.00         3\n",
      "          71       0.00      0.00      0.00        27\n",
      "          72       0.00      0.00      0.00        50\n",
      "          73       0.00      0.00      0.00       103\n",
      "          74       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00        50\n",
      "          76       0.00      0.00      0.00        50\n",
      "          77       0.00      0.00      0.00        50\n",
      "          78       0.00      0.00      0.00        16\n",
      "          79       0.00      0.00      0.00         9\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      3786\n",
      "   macro avg       0.00      0.00      0.00      3786\n",
      "weighted avg       0.00      0.00      0.00      3786\n",
      " samples avg       0.00      0.00      0.00      3786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "43a64d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IPR013419'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enc.classes_)[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e153aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# num_classes = 83\n",
    "# # Compute precision, recall, and thresholds for each class\n",
    "# precision = dict()\n",
    "# recall = dict()\n",
    "# thresholds = dict()\n",
    "# average_precision = dict()\n",
    "\n",
    "# for i in range(num_classes):  # num_classes is the number of classes\n",
    "#     precision[i], recall[i], thresholds[i] = precision_recall_curve(all_labels[:, i], all_predictions[:, i])\n",
    "#     average_precision[i] = average_precision_score(all_labels[:, i], all_predictions[:, i])\n",
    "\n",
    "# # Compute micro-average precision-recall curve and AUC\n",
    "# precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(all_labels.ravel(), all_predictions.ravel())\n",
    "# average_precision[\"micro\"] = average_precision_score(all_labels, all_predictions, average=\"micro\")\n",
    "\n",
    "# # Compute ROC curve and AUC\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "\n",
    "# for i in range(num_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_predictions[:, i])\n",
    "#     roc_auc[i] = roc_auc_score(all_labels[:, i], all_predictions[:, i])\n",
    "\n",
    "# # Compute micro-average ROC curve and AUC\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_predictions.ravel())\n",
    "# roc_auc[\"micro\"] = roc_auc_score(all_labels, all_predictions, average=\"micro\")\n",
    "\n",
    "# # Split classes into groups of 10\n",
    "# class_groups = [list(range(i, min(i + 10, num_classes))) for i in range(0, num_classes, 10)]\n",
    "\n",
    "# # Plot Precision-Recall and ROC curves for each group\n",
    "# for group in class_groups:\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     # Plot Precision-Recall curve\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.step(recall['micro'], precision['micro'], where='post', label='Micro-average Precision-Recall curve (AUPR = {0:0.2f})'\n",
    "#                  ''.format(average_precision[\"micro\"]))\n",
    "#     for i in group:\n",
    "#         plt.step(recall[i], precision[i], where='post', label='Precision-recall curve of class {0} (AUPR = {1:0.2f})'\n",
    "#                  ''.format(i, average_precision[i]))\n",
    "\n",
    "#     plt.xlabel('Recall')\n",
    "#     plt.ylabel('Precision')\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.title('Precision-Recall curve (Classes {})'.format(group))\n",
    "#     plt.legend(loc=\"best\")\n",
    "\n",
    "#     # Plot ROC curve\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(fpr['micro'], tpr['micro'], label='Micro-average ROC curve (AUC = {0:0.2f})'\n",
    "#                  ''.format(roc_auc[\"micro\"]))\n",
    "#     for i in group:\n",
    "#         plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (AUC = {1:0.2f})'\n",
    "#                  ''.format(i, roc_auc[i]))\n",
    "\n",
    "#     plt.plot([0, 1], [0, 1], 'k--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('ROC curve (Classes {})'.format(group))\n",
    "#     plt.legend(loc=\"best\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b446c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import sklearn\n",
    "\n",
    "# print('The nltk version is {}.'.format(nltk.__version__))\n",
    "# print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cbbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
