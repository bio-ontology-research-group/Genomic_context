{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c622ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 692.14 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.available / (1024.0 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "from datasets import Dataset\n",
    "import os\n",
    "from deepgo.utils import Ontology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4afee737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"WordLevel_tokenizer_trained_InterPro.json\"\n",
    "tokenizer = tokenizer.from_file(tokenizer_path)\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bef36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544998"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "242995ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2966, 754, 2545, 196, 9231, 2817, 7418, 2526, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode(\"WP_265490204 WP_206642677 WP_053312998 WP_251959347 WP_000076573 WP_227526754 WP_218401808 WP_106925592\")\n",
    "test.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "543a8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/toibazd/Most_frequent_IPs.json\", \"r\") as f:\n",
    "    ips = json.load(f)\n",
    "\n",
    "sorted_dict = sorted(ips.items(), key=lambda x: x[1], reverse=True)\n",
    "most_frequent_ips = [item[0] for item in sorted_dict[:100]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84272ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IPR004090', 'IPR011701', 'IPR002514', 'IPR003719', 'IPR002155', 'IPR005750', 'IPR001001', 'IPR004604', 'IPR011603', 'IPR005252']\n"
     ]
    }
   ],
   "source": [
    "print(most_frequent_ips[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "07ba9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019753217697143555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08215891f4e455b9febf54191a03f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018131017684936523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4204bb7ab1424ea408deb1acb00bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21791\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "ip_to_go = defaultdict(list)\n",
    "data_dict = defaultdict(list)\n",
    "enc = MultiLabelBinarizer()\n",
    "new_tsv_filename = \"/home/toibazd/Family_IPs_with_GO.tsv\"\n",
    "go = Ontology('data/go.obo')\n",
    "\n",
    "\n",
    "with open(new_tsv_filename, \"r\") as new_tsvfile:\n",
    "    reader = csv.reader(new_tsvfile, delimiter=\"\\t\")\n",
    "    next(reader)\n",
    "    for row in tqdm(reader):\n",
    "        ip = row[0]  # Assuming the IP is in the first column\n",
    "        go_terms = row[6]  # Assuming the GO terms are in the second column\n",
    "\n",
    "        # Add IP and corresponding GO terms to data_dict\n",
    "        ip_to_go[ip] = go_terms.split(',')\n",
    "\n",
    "\n",
    "with open(\"/home/toibazd/Prot2IP_GO_filtered_MF.tsv\", \"r\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter = \"\\t\")\n",
    "    for row in tqdm(reader):\n",
    "        key = row[0].split(\"prot_\")[1].split(\".\")[0]\n",
    "        iprs = eval(row[1])\n",
    "        \n",
    "        # Filter InterPro IDs that are in the words list\n",
    "#         filtered_iprs = [ipr for ipr in iprs if ipr in most_frequent_ips]\n",
    "        filtered_iprs = iprs\n",
    "        # Save only if there are filtered InterPro IDs\n",
    "        for ip in iprs:\n",
    "            if ip in most_frequent_ips:\n",
    "                for GO in ip_to_go[ip]:\n",
    "                    data_dict[key].extend(list(GO))\n",
    "#                     data_dict[key].extend(list(go.get_ancestors(GO)))\n",
    "\n",
    "one_hot_encoded = enc.fit_transform(data_dict.values())\n",
    "one_hot_encoded_dict = {key: value for key, value in zip(data_dict.keys(), one_hot_encoded)}\n",
    "\n",
    "print(len(one_hot_encoded_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "08b6debe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21791"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_encoded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "122c228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21791"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "746c4145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0: Count 72590\n",
      "Number 1: Count 210693\n",
      "283283\n"
     ]
    }
   ],
   "source": [
    "# Find unique numbers and their counts\n",
    "unique_numbers, counts = np.unique(one_hot_encoded, return_counts=True)\n",
    "all_count = 0\n",
    "# Print the count of each number\n",
    "for number, count in zip(unique_numbers, counts):\n",
    "    all_count+=count\n",
    "    print(f\"Number {number}: Count {count}\")\n",
    "print(all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "efeab11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('BERT_DNN_senteces.json', \"r\") as f:\n",
    "    one_hot_encoded_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "deeb72f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_sentences = {key: value for key, value in one_hot_encoded_sentences.items() if value}\n",
    "len(one_hot_encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f2219cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = one_hot_encoded_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ea88291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20155"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3b43fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(544998, 256, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (token_type_embeddings): Embedding(2, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): None\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Check if CUDA is available and choose device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"/home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final\"\n",
    "\n",
    "model = BertModel.from_pretrained(model_path).cuda()\n",
    "model.pooler = None\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "978dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 1 0 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_encoded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c35dd100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01610732078552246,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 40,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625fcaeb08d44f5b8941ce95fa7f9943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128 # Define your batch size\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "\n",
    "    # Convert lists to tensors and move to device\n",
    "    input_ids = torch.tensor(input_ids_list).cuda()\n",
    "    attention_mask = torch.tensor(attention_mask_list).cuda()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]\n",
    "#     relevant_hidden_states = torch.mean(hidden_states[:, 1:-1, :], dim=1)\n",
    "\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        labels.append(one_hot_encoded_dict[indicator])\n",
    "\n",
    "# Ensure order in embeddings matches order in labels\n",
    "\n",
    "# Now embeddings and labels are stored on the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "620352af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    \n",
    "    neg_counts = [len(embeddings)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "      pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)\n",
    "class_counts = np.array(labels).sum(axis=0)\n",
    "pos_weights = calculate_pos_weights(class_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3dda8cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26., 36., 98.,  3., 63., 60., 53., 48.,  0.,  4.,  4., 43., 95., 97.,\n",
       "        36.,  0., 95., 98., 89., 48., 32., 98., 48., 48., 48., 48., 97., 97.,\n",
       "        60., 98., 52., 46., 98., 98., 98., 78., 52., 43., 20., 26., 38., 38.,\n",
       "        97., 28., 22., 22., 22., 53., 97., 89., 25., 93., 93., 97., 19., 36.,\n",
       "         2., 80., 80., 95., 42., 80., 80., 69.,  1., 48.,  4., 31.,  1., 98.,\n",
       "        36., 25., 60., 98., 22., 95., 10., 48., 22.,  2., 15., 15., 53., 53.,\n",
       "         4., 14., 89., 32., 97., 13., 86., 11., 25., 48., 97., 63., 26., 47.,\n",
       "        36., 93., 93., 32., 36., 13., 57., 98., 57., 57., 15., 97., 97., 97.,\n",
       "         2., 13., 52., 17., 17., 36.,  9., 11.,  1.,  3., 15., 15., 80., 69.,\n",
       "        26., 80., 19., 13., 13., 32., 19., 97., 22., 97.,  0.,  0., 27., 63.,\n",
       "        98., 63., 98., 32., 98., 98., 98., 98., 98., 98., 20., 83., 97., 95.,\n",
       "        88., 42., 98., 63., 36., 97., 63., 22., 71., 86., 18., 14., 86.,  4.,\n",
       "        12., 97., 98., 98., 28., 57., 98., 57., 95., 22., 13., 53., 53., 53.,\n",
       "        53., 15., 15., 53., 53., 15., 98., 53., 53., 17., 22., 15., 15., 85.,\n",
       "        66., 97., 97., 86., 23., 52., 95., 97., 97., 97.,  0., 22., 97., 97.,\n",
       "        20., 46., 36., 98., 98., 91., 80., 68., 38., 37., 37., 20., 26., 36.,\n",
       "        95., 16., 85., 36., 23., 98., 31., 66., 40., 42., 91., 80., 80., 42.,\n",
       "        95., 38., 85., 95., 95., 22., 22., 22., 22., 97.,  2., 14., 60., 36.,\n",
       "        22., 14., 63., 98., 31., 98., 63., 23., 98.,  7., 31., 31., 95., 22.,\n",
       "        18., 97., 46., 64., 64.,  3., 27., 15., 15., 98., 17., 88., 11., 95.,\n",
       "        52., 23.,  3., 12., 57., 38., 28., 31., 97., 48., 23., 23., 12., 18.,\n",
       "        18., 95., 95., 32.,  9., 93., 11., 15., 53., 97., 46., 38., 17., 78.,\n",
       "        86., 86., 98.,  4., 23., 98.,  8., 31., 48., 97., 97., 48., 22., 22.,\n",
       "        57.,  8., 45., 14., 11., 97., 15., 10., 13., 30., 27., 37., 10., 37.,\n",
       "        20.,  2., 20., 48., 48., 15., 66., 66., 34., 97.,  4., 22., 98., 97.,\n",
       "        97., 80., 80., 25., 48.,  3.,  4.,  4., 31., 48., 22., 15., 13., 22.,\n",
       "        22., 22., 22., 22., 22., 89., 48., 95., 95., 38.,  1., 10., 45., 26.,\n",
       "        91.,  4.,  2., 57., 15., 19., 97., 98., 98., 98., 22., 19., 95., 22.,\n",
       "        52., 97., 52., 52., 23., 57., 98., 97., 95., 95., 95., 95., 91., 91.,\n",
       "        95., 93., 93., 36., 95.,  2.,  3.,  7.,  2., 98., 36., 36., 36., 36.,\n",
       "        10., 13., 36., 66., 98.,  1.,  1., 14.,  4., 45.,  6., 98.,  6., 22.,\n",
       "        25., 69., 97., 53., 95., 22., 15., 36., 22., 98.,  2., 45., 13., 36.,\n",
       "        32., 42., 42., 97., 52., 57., 16., 16., 13., 22., 97.,  3.,  3., 97.,\n",
       "        32., 23., 23., 98., 13., 98.,  4., 10., 15., 97., 97., 23., 98., 16.,\n",
       "        98., 98., 97., 34., 98., 32., 98., 13.,  1., 19., 14., 22., 98., 15.,\n",
       "        15., 95., 95., 97., 97.,  3., 13.,  2.,  3., 48., 97.,  1., 32.,  7.,\n",
       "        14., 93., 63., 97., 98., 18.,  4., 18., 97., 21., 36., 36., 21., 57.,\n",
       "        12., 14., 95.,  3., 98., 15.,  2., 45.,  8.,  2., 95.,  4., 22.,  6.,\n",
       "        14.,  4., 21., 36., 95., 95., 26., 22., 98., 15., 91., 91., 23., 97.])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7cad879a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f1476691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1fc1f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Zip the lists together\n",
    "combined = list(zip(embeddings, labels))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Unzip the shuffled list\n",
    "embeddings, labels = zip(*combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d7184dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f832c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classification_V0(nn.Module):\n",
    "    def __init__(self, input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob):\n",
    "        super(Classification_V0, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, first_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_hidden, second_hidden)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_hidden, last_hidden)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(last_hidden, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 256\n",
    "first_hidden = 128\n",
    "second_hidden = 64\n",
    "last_hidden = 32\n",
    "output_dim = 546\n",
    "dropout_prob = 0.25\n",
    "\n",
    "clf_model = Classification_V0(input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7d9abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "batch_size = 128\n",
    "def data_generator(embeddings, labels, batch_size):\n",
    "    num_samples = len(embeddings)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_embeddings = embeddings[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        yield batch_embeddings, batch_labels\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(clf_model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.05)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ad1b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020379304885864258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3121890380859376\n",
      "Epoch 2/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01959705352783203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1959642059326172\n",
      "Epoch 3/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019585609436035156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0968857772827147\n",
      "Epoch 4/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0210721492767334,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0474103073120118\n",
      "Epoch 5/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01964426040649414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993632400512695\n",
      "Epoch 6/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019530773162841797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9455679855346679\n",
      "Epoch 7/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019689083099365234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9015768463134766\n",
      "Epoch 8/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01957416534423828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8561732803344727\n",
      "Epoch 9/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019544124603271484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8191336502075195\n",
      "Epoch 10/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019666194915771484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7900764724731445\n",
      "Epoch 11/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019501686096191406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7697283966064453\n",
      "Epoch 12/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019567012786865234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7600112854003906\n",
      "Epoch 13/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019693374633789062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631593139648437\n",
      "Epoch 14/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01950812339782715,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7577664962768554\n",
      "Epoch 15/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019474267959594727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568113571166992\n",
      "Epoch 16/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019739389419555664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7551191360473632\n",
      "Epoch 17/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019532442092895508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539137634277344\n",
      "Epoch 18/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01942753791809082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7533470809936523\n",
      "Epoch 19/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01946735382080078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7519870681762695\n",
      "Epoch 20/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019558191299438477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7474320556640625\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 20\n",
    "epoch_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    \n",
    "    # Initialize data generator\n",
    "    generator = data_generator(embeddings, labels, batch_size)\n",
    "    train_loss = 0\n",
    "    # Iterate over batches\n",
    "    for batch_embeddings, batch_labels in tqdm(generator, desc=\"Training Batches\", leave=False):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert data to tensors\n",
    "\n",
    "        batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_labels_tensor = torch.tensor(batch_labels, dtype = torch.float32)\n",
    "        batch_labels_tensor = batch_labels_tensor.squeeze()\n",
    "\n",
    "        \n",
    "        outputs = clf_model(batch_embeddings_tensor)\n",
    "\n",
    "        \n",
    "        loss = criterion(outputs, batch_labels_tensor)\n",
    "\n",
    "        \n",
    "        train_loss+=loss.item()\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    epoch_loss.append(train_loss/(len(embeddings)/batch_size))\n",
    "    print(train_loss/(len(embeddings)/batch_size))\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0aae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT_DNN_senteces_test.json', \"r\") as f:\n",
    "    test_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9ab316ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = {key: value for key, value in test_sentences.items() if value}\n",
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e3e213bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = test_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0a93cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7d499e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015955448150634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 40,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42b9a08336941c1b36bc24fa17d8222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128 # Define your batch size\n",
    "# model.cuda()\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "    # Convert lists to tensors and move to device\n",
    "    try:\n",
    "        input_ids = torch.tensor(input_ids_list)\n",
    "    except:\n",
    "        for ins in input_ids_list:\n",
    "            if len(ins)!=42:\n",
    "                print(len(ins))\n",
    "                print(ins)\n",
    "    attention_mask = torch.tensor(attention_mask_list)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]\n",
    "#     relevant_hidden_states = torch.mean(hidden_states[:, 1:-1, :], dim=1)\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        test_embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        test_labels.append(one_hot_encoded_dict[indicator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1b5d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e6194248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_V0(\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=32, out_features=546, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9642349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021149158477783203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluation Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = data_generator(test_embeddings, test_labels, batch_size)\n",
    "# Iterate over batches\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "# Initialize lists to store predictions and labels across all batches\n",
    "# Iterate over batches\n",
    "count = 0\n",
    "for batch_embeddings, batch_labels in tqdm(generator, desc=\"Evaluation Batches\", leave=False):\n",
    "    batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "    batch_labels = np.array(batch_labels)\n",
    "    \n",
    "    logits = clf_model(batch_embeddings_tensor)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "    thresholded_predictions = (predictions > 0.7).float()\n",
    "    all_predictions.append(thresholded_predictions.detach().numpy())\n",
    "    all_labels.append(batch_labels)\n",
    "    all_probs.append(predictions.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6a8783cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dd77c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "41649db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 546)\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7cc0ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate predictions and labels across all batches\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_probs = np.concatenate(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3a17e99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 546)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "492e8479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8028767263704124\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y = all_labels.flatten()\n",
    "pred_y = all_probs.flatten()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred_y)\n",
    "print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "10c9315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "541ab895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "546\n"
     ]
    }
   ],
   "source": [
    "cl_report = multilabel_confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Classification report:\")\n",
    "print(len(cl_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5563973c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4528,  288],\n",
       "       [ 102,   82]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_report[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6bb7d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predictions, zero_division=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "93ae8c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.700e+02, 2.580e+02, 1.590e+02, 3.240e+02, 1.570e+02, 1.790e+02,\n",
       "       1.360e+02, 2.130e+02, 4.002e+03, 2.540e+02, 2.590e+02, 1.540e+02,\n",
       "       1.490e+02, 4.000e+01, 2.460e+02, 0.000e+00, 2.030e+02, 1.260e+02,\n",
       "       1.320e+02, 2.140e+02, 9.300e+01, 8.100e+01, 3.440e+02, 1.650e+02,\n",
       "       2.580e+02, 3.030e+02, 1.990e+02, 2.090e+02, 1.500e+02, 2.260e+02,\n",
       "       1.810e+02, 2.500e+02, 0.000e+00, 6.800e+01, 0.000e+00, 1.020e+02,\n",
       "       1.500e+02, 7.700e+01, 1.440e+02, 1.680e+02, 3.470e+02, 1.900e+02,\n",
       "       7.500e+01, 1.300e+01, 2.140e+02, 2.150e+02, 2.150e+02, 1.360e+02,\n",
       "       1.810e+02, 3.500e+01, 1.920e+02, 9.600e+01, 1.850e+02, 1.220e+02,\n",
       "       2.060e+02, 2.550e+02, 9.400e+01, 1.620e+02, 1.590e+02, 1.120e+02,\n",
       "       2.380e+02, 1.630e+02, 1.620e+02, 1.830e+02, 2.790e+02, 9.800e+01,\n",
       "       3.230e+02, 2.930e+02, 2.460e+02, 1.750e+02, 2.450e+02, 5.800e+01,\n",
       "       1.270e+02, 2.410e+02, 2.130e+02, 1.640e+02, 4.450e+02, 1.960e+02,\n",
       "       2.140e+02, 3.880e+02, 3.350e+02, 3.330e+02, 1.350e+02, 1.360e+02,\n",
       "       2.110e+02, 2.130e+02, 8.300e+01, 1.040e+02, 1.660e+02, 2.200e+02,\n",
       "       1.620e+02, 2.330e+02, 1.500e+02, 2.220e+02, 4.000e+00, 1.820e+02,\n",
       "       1.470e+02, 4.100e+01, 2.540e+02, 1.360e+02, 1.590e+02, 2.700e+01,\n",
       "       2.330e+02, 2.930e+02, 2.630e+02, 1.710e+02, 1.400e+02, 1.420e+02,\n",
       "       3.310e+02, 1.930e+02, 2.040e+02, 1.490e+02, 4.470e+02, 3.300e+02,\n",
       "       1.620e+02, 2.800e+02, 2.830e+02, 2.890e+02, 3.990e+02, 3.920e+02,\n",
       "       4.220e+02, 1.460e+02, 2.170e+02, 1.760e+02, 1.590e+02, 2.040e+02,\n",
       "       2.390e+02, 1.660e+02, 2.050e+02, 2.140e+02, 2.230e+02, 7.700e+01,\n",
       "       2.060e+02, 1.290e+02, 2.200e+01, 2.550e+02, 0.000e+00, 0.000e+00,\n",
       "       3.230e+02, 1.970e+02, 1.070e+02, 1.720e+02, 1.020e+02, 2.900e+01,\n",
       "       9.400e+01, 1.100e+01, 1.300e+01, 1.010e+02, 1.470e+02, 1.170e+02,\n",
       "       2.840e+02, 0.000e+00, 5.560e+02, 1.630e+02, 0.000e+00, 2.100e+02,\n",
       "       1.560e+02, 1.740e+02, 2.080e+02, 1.500e+02, 1.910e+02, 2.130e+02,\n",
       "       2.370e+02, 3.470e+02, 2.170e+02, 2.260e+02, 2.610e+02, 6.580e+02,\n",
       "       4.180e+02, 1.690e+02, 2.020e+02, 2.110e+02, 2.800e+02, 1.550e+02,\n",
       "       1.490e+02, 2.580e+02, 1.640e+02, 2.150e+02, 3.300e+02, 1.380e+02,\n",
       "       1.350e+02, 1.360e+02, 1.370e+02, 3.380e+02, 3.340e+02, 1.360e+02,\n",
       "       1.330e+02, 3.350e+02, 2.430e+02, 1.360e+02, 1.350e+02, 2.230e+02,\n",
       "       2.090e+02, 3.340e+02, 3.340e+02, 2.510e+02, 3.000e+02, 1.870e+02,\n",
       "       1.780e+02, 3.530e+02, 2.130e+02, 1.460e+02, 1.730e+02, 1.690e+02,\n",
       "       1.380e+02, 7.000e+00, 0.000e+00, 2.140e+02, 5.600e+01, 5.200e+01,\n",
       "       2.880e+02, 2.360e+02, 2.140e+02, 1.050e+02, 1.210e+02, 1.960e+02,\n",
       "       1.610e+02, 9.600e+01, 3.640e+02, 2.040e+02, 1.320e+02, 3.510e+02,\n",
       "       3.040e+02, 2.140e+02, 1.530e+02, 2.370e+02, 1.860e+02, 2.040e+02,\n",
       "       2.610e+02, 1.150e+02, 4.420e+02, 2.920e+02, 2.700e+02, 2.380e+02,\n",
       "       5.700e+01, 1.560e+02, 1.590e+02, 2.330e+02, 4.700e+01, 2.910e+02,\n",
       "       2.110e+02, 1.060e+02, 1.680e+02, 2.150e+02, 2.140e+02, 2.150e+02,\n",
       "       2.140e+02, 1.880e+02, 2.930e+02, 2.370e+02, 1.170e+02, 2.210e+02,\n",
       "       2.130e+02, 2.840e+02, 2.020e+02, 1.420e+02, 3.810e+02, 1.600e+01,\n",
       "       1.750e+02, 2.240e+02, 1.000e+00, 2.100e+02, 1.390e+02, 1.460e+02,\n",
       "       1.500e+02, 2.150e+02, 2.060e+02, 1.600e+02, 2.200e+02, 1.750e+02,\n",
       "       1.990e+02, 4.240e+02, 3.240e+02, 2.240e+02, 2.360e+02, 1.080e+02,\n",
       "       3.130e+02, 1.000e+00, 4.650e+02, 1.660e+02, 2.820e+02, 3.220e+02,\n",
       "       6.400e+01, 1.270e+02, 1.400e+02, 3.420e+02, 8.000e+00, 2.900e+02,\n",
       "       1.720e+02, 2.120e+02, 2.210e+02, 2.170e+02, 2.180e+02, 2.190e+02,\n",
       "       2.180e+02, 2.700e+02, 2.450e+02, 6.700e+01, 3.360e+02, 2.700e+01,\n",
       "       3.300e+02, 3.210e+02, 1.430e+02, 4.630e+02, 9.200e+01, 3.100e+02,\n",
       "       2.190e+02, 8.600e+01, 6.330e+02, 3.200e+02, 3.170e+02, 3.570e+02,\n",
       "       2.510e+02, 7.600e+01, 4.550e+02, 2.910e+02, 2.170e+02, 4.000e+00,\n",
       "       5.100e+01, 2.880e+02, 2.070e+02, 2.060e+02, 2.960e+02, 4.710e+02,\n",
       "       2.530e+02, 2.120e+02, 3.690e+02, 1.140e+02, 3.340e+02, 4.520e+02,\n",
       "       3.070e+02, 2.610e+02, 2.430e+02, 1.900e+02, 2.840e+02, 3.130e+02,\n",
       "       2.610e+02, 8.500e+01, 2.800e+02, 3.790e+02, 2.480e+02, 3.670e+02,\n",
       "       3.600e+02, 3.570e+02, 1.450e+02, 1.350e+02, 3.070e+02, 2.140e+02,\n",
       "       1.260e+02, 1.000e+00, 6.400e+01, 1.670e+02, 1.650e+02, 2.210e+02,\n",
       "       2.060e+02, 3.550e+02, 3.350e+02, 3.340e+02, 2.970e+02, 2.140e+02,\n",
       "       2.140e+02, 2.230e+02, 2.150e+02, 2.130e+02, 2.140e+02, 2.100e+02,\n",
       "       2.140e+02, 2.140e+02, 2.140e+02, 2.800e+01, 2.160e+02, 2.000e+02,\n",
       "       2.370e+02, 9.800e+01, 3.950e+02, 4.230e+02, 2.470e+02, 1.940e+02,\n",
       "       1.420e+02, 3.520e+02, 4.190e+02, 1.340e+02, 2.060e+02, 2.140e+02,\n",
       "       2.110e+02, 1.490e+02, 1.700e+01, 3.000e+01, 2.110e+02, 2.060e+02,\n",
       "       1.720e+02, 2.150e+02, 1.660e+02, 1.230e+02, 1.520e+02, 1.470e+02,\n",
       "       2.140e+02, 1.490e+02, 1.190e+02, 1.810e+02, 1.660e+02, 1.380e+02,\n",
       "       1.770e+02, 1.520e+02, 1.170e+02, 6.600e+01, 9.100e+01, 1.820e+02,\n",
       "       1.090e+02, 2.420e+02, 1.670e+02, 3.650e+02, 3.900e+02, 3.440e+02,\n",
       "       2.860e+02, 1.330e+02, 2.390e+02, 2.430e+02, 2.440e+02, 2.710e+02,\n",
       "       4.540e+02, 3.830e+02, 2.480e+02, 3.410e+02, 3.780e+02, 4.290e+02,\n",
       "       3.970e+02, 2.250e+02, 6.600e+02, 3.820e+02, 5.980e+02, 1.810e+02,\n",
       "       4.510e+02, 2.140e+02, 2.860e+02, 1.910e+02, 2.800e+02, 1.350e+02,\n",
       "       1.810e+02, 2.060e+02, 3.330e+02, 2.220e+02, 2.130e+02, 3.130e+02,\n",
       "       4.380e+02, 2.020e+02, 2.520e+02, 2.120e+02, 1.720e+02, 2.170e+02,\n",
       "       2.510e+02, 1.510e+02, 2.390e+02, 2.570e+02, 2.060e+02, 2.120e+02,\n",
       "       2.230e+02, 2.140e+02, 4.900e+01, 1.750e+02, 2.030e+02, 2.600e+01,\n",
       "       1.110e+02, 2.140e+02, 2.060e+02, 2.200e+01, 2.190e+02, 2.340e+02,\n",
       "       1.490e+02, 3.330e+02, 2.120e+02, 5.000e+01, 1.540e+02, 2.140e+02,\n",
       "       3.990e+02, 2.150e+02, 6.500e+01, 1.180e+02, 2.500e+02, 1.930e+02,\n",
       "       2.120e+02, 9.800e+01, 8.900e+01, 3.450e+02, 4.310e+02, 2.420e+02,\n",
       "       2.110e+02, 2.130e+02, 1.150e+02, 3.370e+02, 3.340e+02, 1.670e+02,\n",
       "       1.770e+02, 1.770e+02, 1.900e+01, 2.780e+02, 3.790e+02, 4.120e+02,\n",
       "       4.310e+02, 2.060e+02, 1.400e+02, 2.560e+02, 4.700e+01, 0.000e+00,\n",
       "       2.920e+02, 2.070e+02, 1.720e+02, 5.200e+01, 1.260e+02, 2.220e+02,\n",
       "       9.200e+01, 7.700e+01, 1.580e+02, 2.760e+02, 2.140e+02, 2.270e+02,\n",
       "       3.100e+02, 2.490e+02, 3.660e+02, 3.460e+02, 1.650e+02, 3.080e+02,\n",
       "       1.380e+02, 3.330e+02, 4.540e+02, 2.370e+02, 4.740e+02, 3.580e+02,\n",
       "       1.490e+02, 5.450e+02, 2.150e+02, 5.940e+02, 2.430e+02, 6.400e+02,\n",
       "       3.320e+02, 2.200e+02, 1.450e+02, 1.640e+02, 3.620e+02, 2.150e+02,\n",
       "       1.260e+02, 2.400e+02, 9.000e+00, 6.500e+01, 2.140e+02, 3.600e+01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "924972e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.45      0.30       184\n",
      "           1       0.35      0.67      0.46       135\n",
      "           2       0.30      0.96      0.46        50\n",
      "           3       0.83      0.27      0.41      1008\n",
      "           4       0.35      0.71      0.47        77\n",
      "           5       0.21      0.47      0.29        81\n",
      "           6       0.35      0.52      0.42        92\n",
      "           7       0.45      0.95      0.61       100\n",
      "           8       1.00      0.80      0.89      5000\n",
      "           9       0.89      0.25      0.39       907\n",
      "          10       0.87      0.25      0.39       907\n",
      "          11       0.18      0.25      0.21       113\n",
      "          12       0.01      0.04      0.02        52\n",
      "          13       0.03      0.02      0.02        51\n",
      "          14       0.35      0.65      0.46       133\n",
      "          15        nan      0.00      0.00      3414\n",
      "          16       0.14      0.54      0.22        52\n",
      "          17       0.38      0.96      0.55        50\n",
      "          18       0.02      0.04      0.02        55\n",
      "          19       0.45      0.96      0.61       100\n",
      "          20       0.29      0.18      0.22       150\n",
      "          21       0.00      0.00      0.00        50\n",
      "          22       0.13      0.46      0.21       100\n",
      "          23       0.33      0.54      0.41       100\n",
      "          24       0.25      0.64      0.36       101\n",
      "          25       0.18      0.54      0.27       101\n",
      "          26       0.15      0.57      0.23        51\n",
      "          27       0.14      0.57      0.22        51\n",
      "          28       0.20      0.37      0.26        81\n",
      "          29       0.11      0.50      0.18        50\n",
      "          30       0.35      0.68      0.47        94\n",
      "          31       0.27      0.65      0.38       105\n",
      "          32        nan      0.00      0.00        50\n",
      "          33       0.13      0.18      0.15        50\n",
      "          34        nan      0.00      0.00        50\n",
      "          35       0.19      0.30      0.23        63\n",
      "          36       0.43      0.70      0.53        93\n",
      "          37       0.23      0.16      0.19       113\n",
      "          38       0.20      0.12      0.15       236\n",
      "          39       0.13      0.12      0.12       185\n",
      "          40       0.12      0.33      0.18       126\n",
      "          41       0.12      0.18      0.15       126\n",
      "          42       0.01      0.02      0.02        51\n",
      "          43       0.23      0.02      0.03       172\n",
      "          44       0.90      0.91      0.91       212\n",
      "          45       0.97      0.98      0.97       212\n",
      "          46       0.97      0.98      0.97       212\n",
      "          47       0.64      0.95      0.76        92\n",
      "          48       0.23      0.80      0.35        51\n",
      "          49       0.09      0.05      0.07        55\n",
      "          50       0.15      0.15      0.15       188\n",
      "          51       0.20      0.36      0.26        53\n",
      "          52       0.12      0.42      0.18        53\n",
      "          53       0.33      0.78      0.46        51\n",
      "          54       0.90      0.78      0.84       239\n",
      "          55       0.35      0.66      0.45       133\n",
      "          56       0.89      0.06      0.11      1395\n",
      "          57       0.35      0.93      0.51        61\n",
      "          58       0.36      0.93      0.52        61\n",
      "          59       0.06      0.13      0.09        52\n",
      "          60       0.29      0.59      0.39       115\n",
      "          61       0.36      0.95      0.52        61\n",
      "          62       0.36      0.95      0.52        61\n",
      "          63       0.29      0.75      0.42        71\n",
      "          64       0.95      0.14      0.25      1879\n",
      "          65       0.40      0.39      0.39       100\n",
      "          66       0.78      0.28      0.42       882\n",
      "          67       0.25      0.49      0.33       152\n",
      "          68       0.93      0.12      0.21      1886\n",
      "          69       0.05      0.16      0.07        50\n",
      "          70       0.36      0.66      0.47       133\n",
      "          71       0.53      0.16      0.25       190\n",
      "          72       0.28      0.44      0.35        81\n",
      "          73       0.11      0.52      0.18        50\n",
      "          74       0.87      0.87      0.87       214\n",
      "          75       0.27      0.85      0.41        52\n",
      "          76       0.80      0.83      0.81       432\n",
      "          77       0.13      0.25      0.17       102\n",
      "          78       0.90      0.91      0.91       212\n",
      "          79       0.93      0.24      0.38      1509\n",
      "          80       0.88      0.97      0.93       304\n",
      "          81       0.88      0.96      0.92       304\n",
      "          82       0.65      0.96      0.78        92\n",
      "          83       0.65      0.96      0.77        92\n",
      "          84       0.89      0.22      0.35       848\n",
      "          85       0.88      0.59      0.71       316\n",
      "          86       0.05      0.07      0.06        55\n",
      "          87       0.28      0.19      0.23       150\n",
      "          88       0.26      0.84      0.40        51\n",
      "          89       0.85      0.56      0.68       336\n",
      "          90       0.13      0.37      0.19        57\n",
      "          91       0.81      0.47      0.60       396\n",
      "          92       0.16      0.13      0.14       188\n",
      "          93       0.43      0.96      0.60       100\n",
      "          94       0.00      0.00      0.00        51\n",
      "          95       0.30      0.71      0.42        77\n",
      "          96       0.36      0.30      0.33       179\n",
      "          97       0.00      0.00      0.00       104\n",
      "          98       0.34      0.65      0.45       133\n",
      "          99       0.11      0.28      0.16        53\n",
      "         100       0.13      0.38      0.19        53\n",
      "         101       0.00      0.00      0.00       150\n",
      "         102       0.37      0.65      0.47       133\n",
      "         103       0.59      0.51      0.55       338\n",
      "         104       0.18      0.56      0.28        85\n",
      "         105       0.28      0.96      0.43        50\n",
      "         106       0.56      0.92      0.69        85\n",
      "         107       0.55      0.92      0.69        85\n",
      "         108       0.81      0.88      0.85       305\n",
      "         109       0.22      0.84      0.35        51\n",
      "         110       0.21      0.82      0.33        51\n",
      "         111       0.28      0.80      0.41        51\n",
      "         112       0.91      0.25      0.40      1594\n",
      "         113       0.88      0.82      0.85       354\n",
      "         114       0.40      0.70      0.51        93\n",
      "         115       0.81      0.86      0.83       264\n",
      "         116       0.80      0.86      0.83       264\n",
      "         117       0.31      0.67      0.43       135\n",
      "         118       0.80      0.66      0.72       484\n",
      "         119       0.79      0.76      0.77       406\n",
      "         120       0.95      0.19      0.32      2097\n",
      "         121       0.73      0.09      0.16      1184\n",
      "         122       0.40      0.29      0.34       295\n",
      "         123       0.45      0.27      0.34       295\n",
      "         124       0.36      0.93      0.52        61\n",
      "         125       0.28      0.80      0.41        71\n",
      "         126       0.32      0.41      0.36       184\n",
      "         127       0.35      0.95      0.51        61\n",
      "         128       0.91      0.78      0.84       239\n",
      "         129       0.87      0.55      0.68       336\n",
      "         130       0.84      0.56      0.67       336\n",
      "         131       0.26      0.13      0.18       150\n",
      "         132       0.90      0.78      0.84       239\n",
      "         133       0.05      0.14      0.08        51\n",
      "         134       0.00      0.00      0.00       213\n",
      "         135       0.11      0.57      0.19        51\n",
      "         136        nan      0.00      0.00      3819\n",
      "         137        nan      0.00      0.00      2541\n",
      "         138       0.31      0.57      0.40       177\n",
      "         139       0.26      0.68      0.38        77\n",
      "         140       0.45      0.96      0.61        50\n",
      "         141       0.31      0.70      0.43        77\n",
      "         142       0.37      0.76      0.50        50\n",
      "         143       0.00      0.00      0.00       150\n",
      "         144       0.10      0.18      0.12        50\n",
      "         145       0.00      0.00      0.00        50\n",
      "         146       0.00      0.00      0.00        50\n",
      "         147       0.04      0.08      0.05        50\n",
      "         148       0.33      0.96      0.49        50\n",
      "         149       0.39      0.92      0.55        50\n",
      "         150       0.49      0.59      0.54       237\n",
      "         151        nan      0.00      0.00        59\n",
      "         152       0.05      0.51      0.09        51\n",
      "         153       0.28      0.87      0.42        52\n",
      "         154        nan      0.00      0.00        56\n",
      "         155       0.31      0.57      0.41       115\n",
      "         156       0.04      0.14      0.07        50\n",
      "         157       0.32      0.71      0.44        77\n",
      "         158       0.60      0.92      0.72       135\n",
      "         159       0.27      0.78      0.40        51\n",
      "         160       0.29      0.71      0.41        77\n",
      "         161       0.87      0.87      0.87       214\n",
      "         162       0.14      0.49      0.22        69\n",
      "         163       0.07      0.44      0.12        57\n",
      "         164       0.36      0.31      0.33       257\n",
      "         165       0.92      0.65      0.76       319\n",
      "         166       0.09      0.40      0.14        57\n",
      "         167       0.76      0.50      0.61       993\n",
      "         168       0.45      0.52      0.48       364\n",
      "         169       0.16      0.53      0.25        51\n",
      "         170       0.24      0.96      0.38        50\n",
      "         171       0.23      0.96      0.37        50\n",
      "         172       0.45      0.74      0.56       170\n",
      "         173       0.50      0.92      0.65        85\n",
      "         174       0.32      0.96      0.48        50\n",
      "         175       0.17      0.51      0.25        85\n",
      "         176       0.27      0.85      0.41        52\n",
      "         177       0.97      0.98      0.97       212\n",
      "         178       0.88      0.82      0.85       354\n",
      "         179       0.64      0.96      0.77        92\n",
      "         180       0.65      0.96      0.78        92\n",
      "         181       0.65      0.96      0.77        92\n",
      "         182       0.64      0.96      0.77        92\n",
      "         183       0.88      0.97      0.92       304\n",
      "         184       0.88      0.97      0.92       304\n",
      "         185       0.65      0.96      0.77        92\n",
      "         186       0.66      0.96      0.78        92\n",
      "         187       0.88      0.97      0.93       304\n",
      "         188       0.05      0.26      0.09        50\n",
      "         189       0.65      0.96      0.77        92\n",
      "         190       0.65      0.96      0.78        92\n",
      "         191       0.83      0.70      0.76       264\n",
      "         192       0.89      0.87      0.88       214\n",
      "         193       0.88      0.97      0.92       304\n",
      "         194       0.88      0.97      0.92       304\n",
      "         195       0.02      0.07      0.03        58\n",
      "         196       0.07      0.27      0.11        74\n",
      "         197       0.22      0.80      0.34        51\n",
      "         198       0.24      0.84      0.38        51\n",
      "         199       0.07      0.46      0.13        57\n",
      "         200       0.87      0.92      0.90       202\n",
      "         201       0.45      0.70      0.54        93\n",
      "         202       0.26      0.87      0.40        52\n",
      "         203       0.24      0.80      0.37        51\n",
      "         204       0.30      0.82      0.44        51\n",
      "         205       0.00      0.00      0.00        51\n",
      "         206        nan      0.00      0.00      3097\n",
      "         207       0.97      0.98      0.97       212\n",
      "         208       0.02      0.02      0.02        51\n",
      "         209       0.10      0.10      0.10        51\n",
      "         210       0.48      0.59      0.53       237\n",
      "         211       0.28      0.63      0.39       105\n",
      "         212       0.54      0.87      0.66       132\n",
      "         213       0.44      0.92      0.59        50\n",
      "         214       0.38      0.92      0.54        50\n",
      "         215       0.07      0.26      0.11        54\n",
      "         216       0.36      0.95      0.52        61\n",
      "         217       0.00      0.00      0.00        72\n",
      "         218       0.23      0.67      0.34       126\n",
      "         219       0.06      0.10      0.08       129\n",
      "         220       0.09      0.09      0.09       129\n",
      "         221       0.38      0.57      0.45       234\n",
      "         222       0.40      0.67      0.50       182\n",
      "         223       0.54      0.87      0.66       132\n",
      "         224       0.05      0.15      0.08        52\n",
      "         225       0.49      0.41      0.45       287\n",
      "         226       0.05      0.17      0.08        58\n",
      "         227       0.56      0.87      0.68       132\n",
      "         228       0.24      0.30      0.27       206\n",
      "         229       0.41      0.94      0.57        50\n",
      "         230       0.22      0.63      0.33       156\n",
      "         231       0.07      0.26      0.10        74\n",
      "         232       0.35      0.78      0.48       121\n",
      "         233       0.28      0.57      0.37       115\n",
      "         234       0.00      0.00      0.00        54\n",
      "         235       0.37      0.93      0.53        61\n",
      "         236       0.36      0.93      0.52        61\n",
      "         237       0.27      0.56      0.37       115\n",
      "         238       0.23      0.21      0.22        52\n",
      "         239       0.26      0.61      0.37       126\n",
      "         240       0.02      0.07      0.03        58\n",
      "         241       0.15      0.31      0.20        52\n",
      "         242       0.11      0.35      0.16        52\n",
      "         243       0.97      0.98      0.97       212\n",
      "         244       0.97      0.98      0.97       212\n",
      "         245       0.97      0.98      0.97       212\n",
      "         246       0.97      0.98      0.97       212\n",
      "         247       0.15      0.57      0.24        51\n",
      "         248       0.92      0.17      0.28      1620\n",
      "         249       0.38      0.28      0.32       324\n",
      "         250       0.35      0.51      0.41        81\n",
      "         251       0.57      0.93      0.71       135\n",
      "         252       0.97      0.98      0.97       212\n",
      "         253       0.44      0.37      0.40       332\n",
      "         254       0.27      0.71      0.39        77\n",
      "         255       0.28      0.80      0.42        50\n",
      "         256       0.29      0.74      0.42       152\n",
      "         257       1.00      0.32      0.48        50\n",
      "         258       0.31      0.71      0.44        77\n",
      "         259       0.33      0.36      0.34       205\n",
      "         260       0.00      0.00      0.00        50\n",
      "         261       0.89      0.31      0.46       593\n",
      "         262       0.33      0.30      0.31       155\n",
      "         263       0.34      0.32      0.33       155\n",
      "         264       0.05      0.13      0.07        52\n",
      "         265       0.90      0.91      0.90       212\n",
      "         266       0.90      0.73      0.81       255\n",
      "         267       0.18      0.57      0.27        51\n",
      "         268       0.31      0.66      0.42       105\n",
      "         269       0.35      0.82      0.49        76\n",
      "         270       0.31      0.82      0.45        76\n",
      "         271       0.89      0.34      0.49      1125\n",
      "         272       0.32      0.58      0.41       177\n",
      "         273       0.83      0.63      0.72       296\n",
      "         274       0.79      0.63      0.70       296\n",
      "         275       0.06      0.12      0.08        50\n",
      "         276       0.59      0.68      0.63       275\n",
      "         277       0.00      0.00      0.00        56\n",
      "         278       0.49      0.56      0.53       410\n",
      "         279       0.27      0.87      0.41        52\n",
      "         280       0.23      0.70      0.35        94\n",
      "         281       0.36      0.57      0.44       205\n",
      "         282       0.94      0.05      0.10      1131\n",
      "         283       0.57      0.20      0.29       371\n",
      "         284       0.56      0.92      0.69        85\n",
      "         285       0.13      0.35      0.19       126\n",
      "         286       0.00      0.00      0.00       172\n",
      "         287       0.33      0.64      0.44       152\n",
      "         288       0.24      0.80      0.37        51\n",
      "         289       0.25      0.51      0.33       101\n",
      "         290       0.32      0.34      0.33       205\n",
      "         291       0.32      0.34      0.33       205\n",
      "         292       0.94      0.57      0.71       364\n",
      "         293       0.95      0.79      0.86       262\n",
      "         294       0.95      0.79      0.86       262\n",
      "         295       0.10      0.50      0.16        52\n",
      "         296       0.11      0.50      0.18        52\n",
      "         297       0.30      0.13      0.18       150\n",
      "         298       0.87      0.59      0.70       492\n",
      "         299       0.04      0.02      0.03        53\n",
      "         300       0.88      0.75      0.81       388\n",
      "         301       0.83      0.88      0.85       305\n",
      "         302       0.62      0.96      0.75        92\n",
      "         303       0.06      0.57      0.11        51\n",
      "         304       0.02      0.02      0.02       105\n",
      "         305       0.10      0.24      0.14       126\n",
      "         306       0.89      0.73      0.80       264\n",
      "         307       0.13      0.17      0.15        63\n",
      "         308       0.05      0.53      0.09        57\n",
      "         309       0.07      0.39      0.12        57\n",
      "         310       0.12      0.76      0.21        50\n",
      "         311       0.73      0.27      0.39       982\n",
      "         312       0.28      0.34      0.31       205\n",
      "         313       0.00      0.00      0.00        50\n",
      "         314       0.94      0.82      0.88       517\n",
      "         315       0.24      0.47      0.32       152\n",
      "         316       0.30      0.66      0.42       100\n",
      "         317       0.00      0.00      0.00        51\n",
      "         318       0.02      0.02      0.02        51\n",
      "         319       0.20      0.56      0.29       101\n",
      "         320       0.90      0.87      0.88       214\n",
      "         321       0.90      0.87      0.89       214\n",
      "         322       0.17      0.58      0.26        85\n",
      "         323       0.91      0.83      0.87       517\n",
      "         324       0.10      0.23      0.14       107\n",
      "         325       0.39      0.25      0.30       333\n",
      "         326       0.80      0.73      0.76       406\n",
      "         327       0.23      0.51      0.32        51\n",
      "         328       0.89      0.97      0.93       304\n",
      "         329       0.80      0.83      0.81       432\n",
      "         330       0.64      0.55      0.59       353\n",
      "         331       0.06      0.09      0.07       159\n",
      "         332       0.33      0.47      0.39       174\n",
      "         333       0.07      0.10      0.08       129\n",
      "         334       0.45      0.29      0.35       440\n",
      "         335       0.04      0.10      0.06       129\n",
      "         336       0.48      0.52      0.50       237\n",
      "         337       0.99      0.06      0.12      1342\n",
      "         338       0.50      0.59      0.55       237\n",
      "         339       0.11      0.41      0.17       102\n",
      "         340       0.12      0.28      0.17       102\n",
      "         341       0.31      0.39      0.35       295\n",
      "         342       0.06      0.28      0.10        74\n",
      "         343       0.06      0.28      0.10        74\n",
      "         344       0.28      0.28      0.28       141\n",
      "         345       0.30      0.78      0.43        51\n",
      "         346       0.81      0.28      0.42       882\n",
      "         347       0.90      0.91      0.91       212\n",
      "         348       0.30      0.76      0.43        50\n",
      "         349       0.00      0.00      0.00        51\n",
      "         350       0.03      0.04      0.03        51\n",
      "         351       0.34      0.93      0.50        61\n",
      "         352       0.35      0.95      0.51        61\n",
      "         353       0.11      0.13      0.12       188\n",
      "         354       0.46      0.94      0.61       100\n",
      "         355       0.78      0.28      0.41      1008\n",
      "         356       0.78      0.26      0.39       982\n",
      "         357       0.75      0.29      0.41       882\n",
      "         358       0.24      0.47      0.32       152\n",
      "         359       0.45      0.96      0.61       100\n",
      "         360       0.97      0.98      0.98       212\n",
      "         361       0.83      0.60      0.70       310\n",
      "         362       0.87      0.56      0.68       336\n",
      "         363       0.97      0.98      0.97       212\n",
      "         364       0.97      0.98      0.97       212\n",
      "         365       0.98      0.97      0.98       212\n",
      "         366       0.97      0.98      0.97       212\n",
      "         367       0.97      0.98      0.98       212\n",
      "         368       0.97      0.98      0.97       212\n",
      "         369       0.00      0.00      0.00        55\n",
      "         370       0.44      0.96      0.61       100\n",
      "         371       0.09      0.35      0.14        52\n",
      "         372       0.07      0.31      0.11        52\n",
      "         373       0.55      0.42      0.48       128\n",
      "         374       0.97      0.22      0.36      1737\n",
      "         375       0.88      0.87      0.87       432\n",
      "         376       0.11      0.24      0.15       107\n",
      "         377       0.28      0.30      0.29       181\n",
      "         378       0.07      0.19      0.10        54\n",
      "         379       0.74      0.27      0.39       982\n",
      "         380       0.84      0.23      0.36      1554\n",
      "         381       0.58      0.92      0.71        85\n",
      "         382       0.90      0.63      0.74       297\n",
      "         383       0.87      0.78      0.82       239\n",
      "         384       0.19      0.78      0.31        51\n",
      "         385       0.32      0.96      0.48        50\n",
      "         386       1.00      0.34      0.51        50\n",
      "         387       0.57      0.34      0.42        50\n",
      "         388       0.98      0.97      0.97       212\n",
      "         389       0.90      0.78      0.84       239\n",
      "         390       0.27      0.88      0.41        52\n",
      "         391       0.97      0.98      0.97       212\n",
      "         392       0.40      0.71      0.51        93\n",
      "         393       0.33      0.80      0.47        51\n",
      "         394       0.43      0.71      0.54        93\n",
      "         395       0.44      0.70      0.54        93\n",
      "         396       0.87      0.92      0.89       202\n",
      "         397       0.52      0.92      0.67        85\n",
      "         398       0.39      0.94      0.56        50\n",
      "         399       0.16      0.57      0.25        51\n",
      "         400       0.28      0.90      0.43        52\n",
      "         401       0.35      0.92      0.51        52\n",
      "         402       0.27      0.90      0.41        52\n",
      "         403       0.30      0.88      0.45        52\n",
      "         404       0.08      0.17      0.11        54\n",
      "         405       0.02      0.02      0.02        54\n",
      "         406       0.03      0.06      0.04        52\n",
      "         407       0.12      0.40      0.18        53\n",
      "         408       0.15      0.30      0.20        53\n",
      "         409       0.36      0.65      0.46       133\n",
      "         410       0.26      0.85      0.40        52\n",
      "         411       0.83      0.21      0.34      1436\n",
      "         412       0.77      0.25      0.38      1175\n",
      "         413       0.67      0.41      0.51       565\n",
      "         414       0.93      0.17      0.29      1539\n",
      "         415       0.35      0.94      0.51        50\n",
      "         416       0.36      0.65      0.46       133\n",
      "         417       0.36      0.66      0.47       133\n",
      "         418       0.36      0.65      0.46       133\n",
      "         419       0.32      0.65      0.43       133\n",
      "         420       0.80      0.84      0.82       432\n",
      "         421       0.73      0.81      0.77       345\n",
      "         422       0.35      0.66      0.46       133\n",
      "         423       0.06      0.30      0.11        74\n",
      "         424       0.10      0.78      0.18        50\n",
      "         425       0.95      0.19      0.32      2122\n",
      "         426       0.99      0.18      0.30      2227\n",
      "         427       0.92      0.65      0.76       319\n",
      "         428       0.78      0.57      0.66       907\n",
      "         429       0.10      0.35      0.15       107\n",
      "         430       0.81      0.69      0.74       701\n",
      "         431       0.27      0.96      0.42        50\n",
      "         432       0.83      0.58      0.68       644\n",
      "         433       0.97      0.98      0.97       212\n",
      "         434       0.57      0.88      0.69       187\n",
      "         435       0.28      0.75      0.40        71\n",
      "         436       0.10      0.53      0.16        51\n",
      "         437       0.65      0.96      0.78        92\n",
      "         438       0.26      0.90      0.40        52\n",
      "         439       0.90      0.87      0.89       214\n",
      "         440       0.89      0.97      0.93       304\n",
      "         441       0.56      0.93      0.70       135\n",
      "         442       0.97      0.98      0.97       212\n",
      "         443       0.07      0.42      0.12        50\n",
      "         444       0.94      0.26      0.41      1594\n",
      "         445       0.09      0.17      0.12       107\n",
      "         446       0.53      0.38      0.44       353\n",
      "         447       0.54      0.87      0.67       132\n",
      "         448       0.49      0.57      0.53       150\n",
      "         449       0.28      0.53      0.37       115\n",
      "         450       0.27      0.60      0.38       115\n",
      "         451       0.16      0.47      0.24        51\n",
      "         452       0.28      0.70      0.40        94\n",
      "         453       0.18      0.54      0.27        85\n",
      "         454       0.90      0.64      0.75       290\n",
      "         455       0.88      0.64      0.74       290\n",
      "         456       0.84      0.56      0.67       336\n",
      "         457       0.90      0.91      0.91       212\n",
      "         458       0.08      0.08      0.08        51\n",
      "         459       0.64      0.09      0.16      1184\n",
      "         460       0.56      0.10      0.16      1184\n",
      "         461       0.04      0.02      0.03        51\n",
      "         462       0.08      0.06      0.07       150\n",
      "         463       0.87      0.91      0.89       204\n",
      "         464       0.90      0.91      0.91       204\n",
      "         465       0.00      0.00      0.00        50\n",
      "         466       0.86      0.56      0.68       336\n",
      "         467       0.10      0.48      0.17        50\n",
      "         468       0.63      0.11      0.19       856\n",
      "         469       0.92      0.71      0.81       432\n",
      "         470       0.88      0.63      0.73       297\n",
      "         471       0.08      0.08      0.08        51\n",
      "         472       0.26      0.78      0.39        51\n",
      "         473       0.87      0.92      0.89       202\n",
      "         474       0.10      0.80      0.18        50\n",
      "         475       0.87      0.64      0.74       290\n",
      "         476       0.00      0.00      0.00        50\n",
      "         477       0.08      0.18      0.11        50\n",
      "         478       0.11      0.53      0.18        51\n",
      "         479       0.21      0.29      0.25       141\n",
      "         480       0.11      0.46      0.18        50\n",
      "         481       0.17      0.11      0.14       150\n",
      "         482       0.01      0.02      0.01        50\n",
      "         483       0.28      0.28      0.28       343\n",
      "         484       0.95      0.18      0.30      2335\n",
      "         485       0.31      0.31      0.31       239\n",
      "         486       0.31      0.20      0.25       324\n",
      "         487       0.97      0.98      0.97       212\n",
      "         488       0.39      0.90      0.55        50\n",
      "         489       0.87      0.97      0.92       304\n",
      "         490       0.87      0.96      0.92       304\n",
      "         491       0.26      0.85      0.40        52\n",
      "         492       0.27      0.92      0.42        52\n",
      "         493       0.23      0.80      0.36        51\n",
      "         494       0.21      0.08      0.11        51\n",
      "         495       0.87      0.21      0.34      1164\n",
      "         496       0.78      0.83      0.81       356\n",
      "         497       0.87      0.22      0.36      1603\n",
      "         498       0.82      0.31      0.45      1159\n",
      "         499       0.47      0.96      0.63       100\n",
      "         500       0.29      0.80      0.43        51\n",
      "         501       0.93      0.14      0.24      1762\n",
      "         502       0.06      0.02      0.03       150\n",
      "         503        nan      0.00      0.00       557\n",
      "         504       0.45      0.40      0.42       332\n",
      "         505       0.10      0.38      0.15        53\n",
      "         506       0.31      0.69      0.43        77\n",
      "         507       0.02      0.02      0.02        51\n",
      "         508       0.37      0.92      0.52        50\n",
      "         509       0.84      0.72      0.77       259\n",
      "         510       0.91      0.10      0.17       882\n",
      "         511       0.45      0.13      0.21       263\n",
      "         512       0.25      0.78      0.38        51\n",
      "         513       0.61      0.77      0.68       220\n",
      "         514       0.58      0.93      0.72       135\n",
      "         515       0.56      0.93      0.70       135\n",
      "         516       0.55      0.78      0.65       220\n",
      "         517       0.17      0.51      0.26        85\n",
      "         518       0.85      0.81      0.83       382\n",
      "         519       0.89      0.93      0.91       332\n",
      "         520       0.10      0.31      0.15        52\n",
      "         521       0.89      0.27      0.41      1008\n",
      "         522       0.07      0.20      0.11        50\n",
      "         523       0.89      0.97      0.93       304\n",
      "         524       0.94      0.27      0.42      1594\n",
      "         525       0.09      0.21      0.13       107\n",
      "         526       0.91      0.83      0.87       517\n",
      "         527       0.87      0.24      0.38      1275\n",
      "         528       0.12      0.35      0.18        52\n",
      "         529       0.84      0.49      0.62       933\n",
      "         530       0.97      0.98      0.97       212\n",
      "         531       0.76      0.65      0.70       698\n",
      "         532       0.86      0.65      0.74       319\n",
      "         533       0.80      0.56      0.66       907\n",
      "         534       0.52      0.78      0.62       220\n",
      "         535       0.58      0.94      0.72       135\n",
      "         536       0.32      0.88      0.47        52\n",
      "         537       0.27      0.85      0.41        52\n",
      "         538       0.21      0.41      0.27       184\n",
      "         539       0.90      0.91      0.90       212\n",
      "         540       0.37      0.92      0.52        50\n",
      "         541       0.78      0.60      0.68       310\n",
      "         542       0.00      0.00      0.00        54\n",
      "         543       0.08      0.09      0.08        54\n",
      "         544       0.87      0.92      0.89       202\n",
      "         545       0.11      0.08      0.09        51\n",
      "\n",
      "   micro avg       0.52      0.41      0.46    151833\n",
      "   macro avg       0.45      0.55      0.43    151833\n",
      "weighted avg       0.72      0.41      0.44    151833\n",
      " samples avg       0.50      0.24      0.24    151833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "21f752be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GO:0000096'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.classes_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e4706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
