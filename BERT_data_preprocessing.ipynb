{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c622ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 335.43 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.available / (1024.0 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8c31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_sentences(input_string, sentence_length=9, step_size=5):\n",
    "    words = input_string.split()\n",
    "    if len(words) < sentence_length:\n",
    "        return [\" \".join(words)]\n",
    "\n",
    "    sentences = []\n",
    "    for i in range(0, len(words) - sentence_length + 1, step_size):\n",
    "        sentences.append(\" \".join(words[i: i + sentence_length])) \n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "\n",
    "def split_data(data, train_ratio=0.8, validate_ratio=0.1, test_ratio=0.1, seed=123):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "    n = len(data)\n",
    "    train_end = int(train_ratio * n)\n",
    "    validate_end = int((train_ratio + validate_ratio) * n)\n",
    "    train_data = data[:train_end]\n",
    "    validate_data = data[train_end:validate_end]\n",
    "    test_data = data[validate_end:]\n",
    "    return train_data, validate_data, test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4afee737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"WordLevel_tokenizer_trained_InterPro.json\"\n",
    "tokenizer = tokenizer.from_file(tokenizer_path)\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bef36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "242995ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2966, 754, 2545, 196, 9231, 2817, 7418, 2526, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode(\"WP_265490204 WP_206642677 WP_053312998 WP_251959347 WP_000076573 WP_227526754 WP_218401808 WP_106925592\")\n",
    "test.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e994a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31002/31002 [00:19<00:00, 1614.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 332.37 GB\n",
      "3902759\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "all_sentences = []\n",
    "absolute_path_genomes = \"/ibex/user/toibazd/InterPro_annotated_genomes/\"\n",
    "\n",
    "for file_name in tqdm(os.listdir(absolute_path_genomes)):\n",
    "    short_sentences = []\n",
    "    with open(os.path.join(absolute_path_genomes, file_name), \"r\", encoding=\"latin-1\") as infile:\n",
    "        content = infile.read()\n",
    "        short_sentences = divide_into_sentences(content)\n",
    "        all_sentences+=short_sentences\n",
    "\n",
    "\n",
    "train_sentences, validation_sentences, test_sentences = split_data(all_sentences)\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "print(len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ba9843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3902759\n",
      "487845\n",
      "Free CPU Memory: 303.30 GB\n",
      "Free CPU Memory: 303.33 GB\n"
     ]
    }
   ],
   "source": [
    "train_inputs = tokenizer.encode_batch(train_sentences)\n",
    "val_inputs = tokenizer.encode_batch(validation_sentences)\n",
    "print(len(train_inputs))\n",
    "print(len(val_inputs))\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "del train_sentences\n",
    "del validation_sentences\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efeab11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902759/3902759 [02:21<00:00, 27608.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint one\n",
      "0\n",
      "Free CPU Memory: 231.64 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487845/487845 [00:17<00:00, 27658.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint one\n",
      "0\n",
      "Free CPU Memory: 222.71 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cpi = 0\n",
    "for inp in tqdm(train_inputs):\n",
    "    inp.pad(256,direction = 'right',pad_id = 3, pad_token = '[PAD]' )\n",
    "    if len(inp.ids) != 256:\n",
    "        cpi+=1\n",
    "        print(len(inp.ids))\n",
    "print(\"Checkpoint one\")\n",
    "print(cpi)\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "cpi = 0\n",
    "for inp in tqdm(val_inputs):\n",
    "    inp.pad(256,direction = 'right',pad_id = 3, pad_token = '[PAD]' )\n",
    "    if len(inp.ids) != 256 and len(inp.attention_mask) != 256:\n",
    "        cpi+=1\n",
    "        print(len(inp.ids))\n",
    "print(\"Checkpoint one\")\n",
    "print(cpi)\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2219cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902759/3902759 [00:58<00:00, 66915.09it/s] \n",
      "100%|██████████| 487845/487845 [00:06<00:00, 74063.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint two\n",
      "Free CPU Memory: 212.70 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902759/3902759 [00:45<00:00, 85112.51it/s] \n",
      "100%|██████████| 487845/487845 [00:04<00:00, 98175.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint three\n",
      "Free CPU Memory: 202.66 GB\n"
     ]
    }
   ],
   "source": [
    "train_input_ids = torch.tensor([i.ids for i in tqdm(train_inputs)])\n",
    "val_input_ids = torch.tensor([i.ids for i in tqdm(val_inputs)])\n",
    "print(\"Checkpoint two\")\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "train_attention_mask = torch.tensor([i.attention_mask for i in tqdm(train_inputs)])\n",
    "val_attention_mask = torch.tensor([i.attention_mask for i in tqdm(val_inputs)])\n",
    "print(\"Checkpoint three\")\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea88291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making MASK for Training\n",
      "Making MASK for Validation\n",
      "Free CPU Memory: 195.48 GB\n",
      "Free CPU Memory: 195.36 GB\n"
     ]
    }
   ],
   "source": [
    "train_ins = {\"input_ids\":train_input_ids,'attention_mask':train_attention_mask}\n",
    "val_ins = {\"input_ids\":val_input_ids,'attention_mask':val_attention_mask}\n",
    "\n",
    "\n",
    "print(\"Making MASK for Training\")\n",
    "train_ins[\"labels\"] = train_ins[\"input_ids\"].detach().clone()\n",
    "# train_ins['labels'] = torch.zeros_like(train_ins['input_ids'])\n",
    "rand = torch.rand(train_ins['input_ids'].shape)\n",
    "\n",
    "train_mask_arr = (rand<0.15)*(train_ins['input_ids'] != 1) * (train_ins['input_ids'] != 3) *(train_ins['input_ids'] != 2)\n",
    "\n",
    "print(\"Making MASK for Validation\")\n",
    "val_ins[\"labels\"] = val_ins[\"input_ids\"].detach().clone()\n",
    "rand = torch.rand(val_ins['input_ids'].shape)\n",
    "\n",
    "val_mask_arr = (rand<0.15)*(val_ins['input_ids'] != 1) * (val_ins['input_ids'] != 3) *(val_ins['input_ids'] != 2)\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "del train_inputs\n",
    "del val_inputs\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c35dd100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3902759/3902759 [00:59<00:00, 65497.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 194.96 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487845/487845 [00:06<00:00, 70969.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 195.34 GB\n"
     ]
    }
   ],
   "source": [
    "selection = []\n",
    "\n",
    "for i in tqdm(range(train_mask_arr.shape[0])):\n",
    "    selection.append(\n",
    "    torch.flatten(train_mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "for i in range(train_mask_arr.shape[0]):\n",
    "#     train_ins[\"labels\"][i, selection[i]] = train_ins['input_ids'][i, selection[i]]\n",
    "    train_ins['input_ids'][i, selection[i]]= 4\n",
    "    \n",
    "    \n",
    "selection = []\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "for i in tqdm(range(val_mask_arr.shape[0])):\n",
    "    selection.append(\n",
    "    torch.flatten(val_mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "for i in range(val_mask_arr.shape[0]):\n",
    "    val_ins['input_ids'][i, selection[i]]= 4\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea41e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 195.31 GB\n",
      "Free CPU Memory: 180.96 GB\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "train_dataset = datasets.Dataset.from_dict(train_ins)\n",
    "val_dataset = Dataset.from_dict(val_ins)\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")\n",
    "train_dataset.set_format(\"pt\")\n",
    "val_dataset.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6a42ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint one\n"
     ]
    }
   ],
   "source": [
    "print(\"Checkpoint one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aae8a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018154382705688477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/27 shards)",
       "rate": null,
       "total": 3902759,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/27 shards):   0%|          | 0/3902759 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.save_to_disk(\"BERT_train_dataset_context5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3e213bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018764019012451172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/4 shards)",
       "rate": null,
       "total": 487845,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/487845 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_dataset.save_to_disk(\"BERT_val_dataset_context5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9282be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93cb03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
