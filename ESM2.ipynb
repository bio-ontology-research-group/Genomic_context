{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609634b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m652.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fair-esm\n",
      "Successfully installed fair-esm-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.pretrained import load_model_and_alphabet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4416310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = load_model_and_alphabet(\"esm2_t6_8M_UR50D\")\n",
    "\n",
    "protein_sequence = \"MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENARIQSKLSDLQKKKIDIDNKLLKEKQNLIKEEILERKKLEVLTKKQQKDEIEHQKKLKREIDAIKASTQYITDVSISSYNNTIPETEPEYDLFISHASEDKEDFVRPLAETLQQLGVNVWYDEFTLKVGDSLRQKIDSGLRNSKYGTVVLSTDFIKKDWTNYELDGLVAREMNGHKMILPIWHKITKNDVLDYSPNLADKVALNTSVNSIEEIAHQLADVILNR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0519a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d727178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 269])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = alphabet.encode(protein_sequence)\n",
    "\n",
    "# Add batch dimension and convert to tensor\n",
    "tokens = torch.tensor([tokens])\n",
    "# repr_layers = [(i + model.num_layers + 1) % (model.num_layers + 1) for i in [-1]]\n",
    "repr_layers = [0,1,2,3,4,5,6,7]\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21378ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference with the model\n",
    "with torch.no_grad():\n",
    "    results = model(tokens, repr_layers = repr_layers)\n",
    "\n",
    "# Extract the embeddings from the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec51ff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 269, 320])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"representations\"][6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dcc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5478f83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([269, 320])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = results[\"representations\"][6][0] # Choose the layer for embeddings\n",
    "\n",
    "# Extract the embeddings for the first token (CLS token)\n",
    "embeddings.shape\n",
    "\n",
    "# Now, protein_embedding contains the embedding for your protein sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "149e0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_embedding = torch.mean(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10b47f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7721e-01, -1.7735e-01,  1.7127e-01,  9.8298e-02,  5.3106e-02,\n",
       "        -3.2027e-02,  1.3972e-01,  5.5670e-02,  1.3723e-01, -1.3610e-01,\n",
       "         1.1724e-01,  1.3129e-01, -3.5700e-01,  3.9118e-02,  1.6550e-01,\n",
       "        -1.4301e-01,  1.5837e-02, -6.1472e-02, -2.0815e-01,  2.7341e-02,\n",
       "         1.5535e-01,  1.2172e-01,  1.2425e-01, -4.1770e-02,  1.9361e-01,\n",
       "         2.0973e-02,  2.8411e-02,  4.2326e-02, -5.8243e-02,  3.1322e-02,\n",
       "        -4.2460e-02,  3.5530e-01,  1.5035e-04,  6.2403e-02,  1.5212e-01,\n",
       "        -1.7816e-01,  1.0537e-01, -6.5052e-02,  8.8650e-02,  1.1628e-02,\n",
       "         2.7614e-01,  1.5463e-01,  7.6862e-02, -4.1604e-01,  6.9021e-02,\n",
       "         1.3729e-02, -7.2016e-01,  9.6697e-02,  1.1913e-01, -1.4245e-01,\n",
       "        -6.7230e-02,  6.0033e-02, -2.2197e-02,  1.1122e-01,  6.1001e-02,\n",
       "        -1.7978e-01,  2.3904e-01, -9.0057e-02,  2.2204e-01, -2.1444e-02,\n",
       "        -4.3397e-02, -1.2551e-01, -3.7581e+00, -1.1936e-01,  2.3572e-02,\n",
       "        -1.9866e-02,  9.2132e-02, -1.4989e-02, -1.2729e-01,  3.8273e-02,\n",
       "         1.5481e-01,  5.1937e-02,  7.1177e-04,  2.2384e-01,  1.6557e-01,\n",
       "        -6.4241e-03,  1.2472e-01,  2.6306e-01, -7.6323e-02,  8.4321e-02,\n",
       "        -7.0710e-02,  6.7395e-02,  2.2214e-01,  4.9670e-02,  2.1437e-01,\n",
       "         1.2922e-01,  1.2744e-01,  8.3369e-02,  1.8089e-02,  1.8620e-01,\n",
       "        -4.3573e-02, -3.2459e-01,  1.0386e-01, -4.7143e-03, -1.0531e-01,\n",
       "        -6.8602e-03, -2.0420e-01, -5.1702e-02, -1.6684e-01,  2.3016e-01,\n",
       "         3.2993e-01, -4.8474e-02, -1.0299e-01,  5.4112e-02,  1.0443e-01,\n",
       "        -2.1790e-02, -3.4938e-03, -5.0877e-02, -8.6057e-02, -5.3312e-02,\n",
       "         1.4751e-01,  3.2474e-03, -1.2577e-01, -8.2649e-02, -9.3883e-02,\n",
       "         1.1593e-01, -1.4088e-01,  1.6471e-01,  1.3519e-01,  4.6048e-02,\n",
       "         6.4007e-02,  1.1926e-01,  8.8114e-02, -3.4329e-01,  2.6847e-01,\n",
       "        -8.2098e-02,  4.4849e-02, -1.6961e-01,  4.6744e-02,  1.4067e-01,\n",
       "        -1.1267e-01,  1.1510e-01, -6.7279e-03, -6.6567e-03,  2.3184e-01,\n",
       "        -1.3631e-01, -1.9367e-01, -9.5584e-02, -1.3869e-01, -2.6968e-01,\n",
       "        -4.8338e-02,  7.6548e-02, -1.1433e-01, -4.4280e-02, -6.2467e-02,\n",
       "         8.3211e-02, -2.8838e-02,  2.0297e-01, -1.3650e-01,  2.2684e-01,\n",
       "         9.7317e-02, -2.9365e-02, -3.6974e-01, -1.4689e-01, -3.4359e-01,\n",
       "         2.3506e-01,  2.7832e-01,  3.1090e-01, -1.0015e-01,  6.9172e-03,\n",
       "         7.7860e-02,  1.0538e-03,  2.2379e-01, -4.7153e-02,  2.3738e-01,\n",
       "        -1.7753e-01,  1.9215e-01, -1.8644e-01, -2.5253e-02,  7.6135e-03,\n",
       "         1.5354e-01, -1.2683e-02,  2.5226e-01, -7.4121e-03, -9.2526e-02,\n",
       "         1.5074e-01,  7.3380e-02, -1.4643e-02, -1.0584e-01, -2.3548e-01,\n",
       "         1.5787e-01, -2.8470e-01, -4.2488e-03,  1.3614e-01, -4.1372e-02,\n",
       "        -1.0039e-01, -3.0119e-01,  2.7144e-01, -1.3571e-01, -6.4531e-02,\n",
       "         2.0023e-03,  5.9191e-02,  1.6382e-02, -3.5490e-02,  2.2076e-01,\n",
       "         1.0585e-01, -7.3880e-02,  7.5256e-02,  1.5231e-01,  2.0352e-01,\n",
       "         5.3977e-02,  2.1405e-02,  1.1637e-01,  1.2349e-01, -1.2759e-02,\n",
       "        -6.7094e-02, -6.0198e-04, -6.1194e-01, -1.9861e-01, -2.9952e-01,\n",
       "         1.4422e-02, -1.9930e-01, -1.0937e-02, -1.4732e-01,  2.0455e-01,\n",
       "        -7.0808e-02,  1.0640e-01, -1.3856e-01, -2.7314e-02,  1.2159e-01,\n",
       "        -2.7440e-01, -3.0677e-01,  1.9050e-01, -1.5886e-01,  1.2514e-01,\n",
       "        -2.5689e-02, -1.3615e-01,  4.6147e-02,  1.7264e-02, -8.0338e-02,\n",
       "         4.6050e-02, -9.1999e-02,  8.1132e-02, -8.0624e-02,  6.6054e-02,\n",
       "        -8.5349e-02,  1.0025e-02,  1.2547e-01,  5.1283e-02, -1.3552e-01,\n",
       "         5.1851e-02, -8.7778e-02, -3.2941e-03, -3.0892e-02, -2.6998e-02,\n",
       "         4.5334e-02,  2.6589e-01,  5.5327e-02, -2.0865e-01,  2.1426e-02,\n",
       "         1.1486e-01, -3.9270e-02,  3.1093e-02, -2.3200e-03,  8.6269e-02,\n",
       "        -3.0524e-02, -7.8932e-02, -3.6093e-03,  1.9143e-01, -9.3067e-02,\n",
       "         1.3834e-01, -6.0657e-02, -3.2952e-01, -4.9280e-02,  3.7723e-02,\n",
       "         1.8295e-01, -2.8555e-02, -4.7172e-01, -4.6023e-03, -8.5424e-02,\n",
       "        -9.7066e-02, -5.1631e-02,  2.0871e-01,  3.7508e-02, -2.0447e-02,\n",
       "         3.8356e-02,  5.6845e-02,  5.0053e-02, -8.2543e-02, -1.4933e-01,\n",
       "         1.0023e-01, -5.8150e-02,  3.5188e-02, -7.9490e-03, -1.4301e-01,\n",
       "         3.1465e-01, -1.2866e-01, -2.1083e-01,  2.6856e-01, -1.3804e-01,\n",
       "        -8.3542e-02, -8.6580e-02, -2.8621e-02, -5.0457e-02, -2.7406e-02,\n",
       "         6.6738e-02,  6.6487e-02, -2.1026e-02,  2.4172e-02,  2.9029e-03,\n",
       "        -1.0466e-01, -1.1189e-01,  2.1828e-01,  4.4632e-02,  1.7854e-02,\n",
       "         9.5732e-03, -7.2973e-02,  5.9648e-02,  1.6167e-01, -1.8025e-01,\n",
       "        -1.0260e-01, -1.0184e-01,  1.0708e-01,  5.7674e-02,  6.8948e-02,\n",
       "        -1.0098e-01, -6.7720e-02,  1.4625e-01, -1.1329e-01, -9.2207e-02])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9086d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
