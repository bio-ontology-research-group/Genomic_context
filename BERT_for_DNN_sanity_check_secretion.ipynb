{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c622ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 249.14 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.available / (1024.0 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afee737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"WordLevel_tokenizer_trained_InterPro.json\"\n",
    "tokenizer = tokenizer.from_file(tokenizer_path)\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bef36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242995ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2966, 754, 2545, 196, 9231, 2817, 7418, 2526, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode(\"WP_265490204 WP_206642677 WP_053312998 WP_251959347 WP_000076573 WP_227526754 WP_218401808 WP_106925592\")\n",
    "test.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5c8709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secretion_IP.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "defense_ips = []\n",
    "directory = \"/home/toibazd/Secretion_InterPros/\"\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    file_path = os.path.join(directory, file)\n",
    "    with open(file_path, 'r', newline='') as infile:\n",
    "        reader = csv.reader(infile, delimiter = \"\\t\")\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            ip = row[0]\n",
    "            defense_ips.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679dec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secretion IPs number:  164\n"
     ]
    }
   ],
   "source": [
    "print(\"Secretion IPs number: \", len(defense_ips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ba9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014180421829223633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fcafb154c7487c87a46ac88021d732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data_dict = defaultdict(list)\n",
    "\n",
    "with open(\"/home/toibazd/Prot2IP.tsv\", \"r\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter = \"\\t\")\n",
    "    for row in tqdm(reader):\n",
    "        key = row[0].split(\"prot_\")[1].split(\".\")[0]\n",
    "        iprs = eval(row[1])\n",
    "\n",
    "        # Save only if there are filtered InterPro IDs\n",
    "        for ip in iprs:\n",
    "            if ip in defense_ips:\n",
    "                data_dict[key].append(ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334d007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_defense = set()\n",
    "\n",
    "# Iterate through each value list in the dictionary and add its elements to the set\n",
    "for value_list in data_dict.values():\n",
    "    unique_defense.update(value_list)\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "unique_defense = list(unique_defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b651fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f471e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "enc = MultiLabelBinarizer()\n",
    "one_hot_encoded = enc.fit_transform(data_dict.values())\n",
    "one_hot_encoded_dict = {key: value for key, value in zip(data_dict.keys(), one_hot_encoded)}\n",
    "\n",
    "print(len(one_hot_encoded_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7464990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4161, 156)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51e75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# directory = '/ibex/user/toibazd/InterPro_annotated_genomes/'\n",
    "# one_hot_encoded_sentences = {}\n",
    "\n",
    "# sentence_length = 40\n",
    "# sentences_per_IP = 600\n",
    "\n",
    "# # Set random seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "# # Randomly choose 1000 files with seed 42\n",
    "# selected_files = os.listdir(directory)\n",
    "\n",
    "\n",
    "# # Define a function to process a file\n",
    "# def process_file(filename, IP):\n",
    "#     sentences = []\n",
    "\n",
    "#     filepath = os.path.join(directory, filename)\n",
    "\n",
    "#     with open(filepath, 'r') as file:\n",
    "#         content = file.read()\n",
    "#         words = content.strip().split()\n",
    "\n",
    "#         # Check if the key is in the file\n",
    "#         for i in range(19, len(words)-20):\n",
    "#             # Shuffle the indices of the words containing the key\n",
    "#             if IP in data_dict[words[i]]:\n",
    "#                 if len(words) - i >= 21:\n",
    "#                     sentence = \" \".join(words[i - 19:i + sentence_length - 19])\n",
    "#                     sentences.append(sentence)\n",
    "#     return sentences\n",
    "\n",
    "\n",
    "# # Iterate over keys\n",
    "# for IP in tqdm(unique_defense):\n",
    "#     one_hot_encoded_sentences[IP] = []\n",
    "#     sentences_count = 0\n",
    "\n",
    "#     # Use ThreadPoolExecutor for concurrent processing\n",
    "#     with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "#         futures = [executor.submit(process_file, filename, IP) for filename in selected_files]\n",
    "#         for future in futures:\n",
    "#             sentences = future.result()\n",
    "#             one_hot_encoded_sentences[IP].extend(sentences)\n",
    "#             sentences_count += len(sentences)\n",
    "#             if sentences_count >= sentences_per_IP:\n",
    "#                 break\n",
    "\n",
    "#     # Break if the required number of sentences per key is reached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abea8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, values in one_hot_encoded_sentences.items():\n",
    "#     print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a55b4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('BERT_sanity_check_secretion_DNN_senteces.json', 'w') as f:\n",
    "#     json.dump(one_hot_encoded_sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeeb70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('BERT_sanity_check_secretion_DNN_senteces.json', \"r\") as f:\n",
    "    one_hot_encoded_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1149a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPR010263 100\n",
      "IPR048130 101\n",
      "IPR006533 102\n",
      "IPR032389 100\n",
      "IPR025955 100\n",
      "IPR012842 100\n",
      "IPR001639 100\n",
      "IPR018920 100\n",
      "IPR017847 102\n",
      "IPR009371 100\n",
      "IPR035576 100\n",
      "IPR013391 100\n",
      "IPR002010 102\n",
      "IPR010586 100\n",
      "IPR017737 100\n",
      "IPR039366 100\n",
      "IPR003895 100\n",
      "IPR010130 101\n",
      "IPR034026 100\n",
      "IPR027282 100\n",
      "IPR009211 100\n",
      "IPR047659 90\n",
      "IPR009863 100\n",
      "IPR003283 100\n",
      "IPR013369 100\n",
      "IPR009929 100\n",
      "IPR021545 100\n",
      "IPR005714 100\n",
      "IPR008312 102\n",
      "IPR034756 100\n",
      "IPR011850 100\n",
      "IPR031758 101\n",
      "IPR025292 100\n",
      "IPR008514 100\n",
      "IPR023835 100\n",
      "IPR010290 100\n",
      "IPR021368 100\n",
      "IPR027628 100\n",
      "IPR022250 100\n",
      "IPR023834 103\n",
      "IPR005696 100\n",
      "IPR049928 100\n",
      "IPR022792 100\n",
      "IPR047695 100\n",
      "IPR004683 100\n",
      "IPR010128 103\n",
      "IPR010129 101\n",
      "IPR026264 100\n",
      "IPR023787 100\n",
      "IPR017739 100\n",
      "IPR019861 110\n",
      "IPR011841 100\n",
      "IPR017740 100\n",
      "IPR018893 100\n",
      "IPR007606 104\n",
      "IPR006304 101\n",
      "IPR017738 100\n",
      "IPR013363 100\n",
      "IPR049875 100\n",
      "IPR049801 16\n",
      "IPR013365 100\n",
      "IPR005838 101\n",
      "IPR005415 100\n",
      "IPR010132 100\n",
      "IPR043993 101\n",
      "IPR017750 100\n",
      "IPR017735 100\n",
      "IPR021055 100\n",
      "IPR005628 100\n",
      "IPR013388 100\n",
      "IPR017033 100\n",
      "IPR007812 100\n",
      "IPR012672 100\n",
      "IPR035177 100\n",
      "IPR032681 100\n",
      "IPR013380 100\n",
      "IPR009483 100\n",
      "IPR017734 100\n",
      "IPR009335 100\n",
      "IPR010272 100\n",
      "IPR047799 100\n",
      "IPR005773 101\n",
      "IPR004355 100\n",
      "IPR005416 100\n",
      "IPR010052 100\n",
      "IPR006307 100\n",
      "IPR010269 100\n",
      "IPR007795 101\n",
      "IPR010054 100\n",
      "IPR048928 17\n",
      "IPR022275 21\n",
      "IPR009510 100\n",
      "IPR003282 100\n",
      "IPR012843 100\n",
      "IPR006135 101\n",
      "IPR010310 111\n",
      "IPR010055 100\n",
      "IPR032032 100\n",
      "IPR022073 102\n",
      "IPR005498 100\n",
      "IPR013349 100\n",
      "IPR030925 81\n",
      "IPR018581 64\n",
      "IPR021477 100\n",
      "IPR012670 100\n",
      "IPR007039 100\n",
      "IPR022797 100\n",
      "IPR013095 100\n",
      "IPR021123 100\n",
      "IPR039449 101\n",
      "IPR013392 100\n",
      "IPR006302 100\n",
      "IPR003522 100\n",
      "IPR013356 100\n",
      "IPR002416 100\n",
      "IPR004357 100\n",
      "IPR017731 100\n",
      "IPR016379 100\n",
      "IPR007690 100\n",
      "IPR012673 100\n",
      "IPR006707 101\n",
      "IPR006306 100\n",
      "IPR009502 100\n",
      "IPR001712 101\n",
      "IPR007792 100\n",
      "IPR016502 100\n",
      "IPR014117 100\n",
      "IPR022536 101\n",
      "IPR003537 100\n",
      "IPR023840 100\n",
      "IPR014155 100\n",
      "IPR018778 100\n",
      "IPR013394 100\n",
      "IPR019029 100\n",
      "IPR049848 100\n",
      "IPR013405 100\n",
      "IPR013390 100\n",
      "IPR001172 100\n",
      "IPR010732 100\n",
      "IPR013348 100\n",
      "IPR016684 100\n",
      "IPR030924 62\n",
      "IPR010437 100\n",
      "IPR003688 100\n",
      "IPR000983 100\n",
      "IPR014158 100\n",
      "IPR031682 100\n",
      "IPR048018 100\n",
      "IPR013393 100\n",
      "IPR013385 100\n",
      "IPR013387 100\n",
      "IPR014575 100\n",
      "IPR013353 100\n",
      "IPR025562 100\n",
      "IPR048081 100\n",
      "IPR030927 64\n"
     ]
    }
   ],
   "source": [
    "for key, value in one_hot_encoded_sentences.items():\n",
    "    print(key, end=\" \")\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deeb72f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_sentences = {key: value for key, value in one_hot_encoded_sentences.items() if value}\n",
    "len(one_hot_encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2219cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = one_hot_encoded_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea88291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15270"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c1c4fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15270\n"
     ]
    }
   ],
   "source": [
    "count= 0\n",
    "for string in matching_string:\n",
    "    words = string.split(\" \")\n",
    "    if not words[19] in data_dict.keys():\n",
    "        print(\"False\")\n",
    "    else:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b43fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-25 13:32:17,251] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(544998, 256, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (token_type_embeddings): Embedding(2, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): None\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Check if CUDA is available and choose device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"/home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final\"\n",
    "\n",
    "model = BertModel.from_pretrained(model_path).cuda()\n",
    "model.pooler = None\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156,)\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_encoded[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c35dd100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017528533935546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 60,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578b7fd47216473ab82c9c6c50d821b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 256 # Define your batch size\n",
    "model.cuda()\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "\n",
    "    # Convert lists to tensors and move to device\n",
    "    input_ids = torch.tensor(input_ids_list).cuda()\n",
    "    attention_mask = torch.tensor(attention_mask_list).cuda()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]  # Extract the 20th token's hidden state\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        labels.append(one_hot_encoded_dict[indicator])\n",
    "\n",
    "# Ensure order in embeddings matches order in labels\n",
    "\n",
    "# Now embeddings and labels are stored on the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cad879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    \n",
    "    neg_counts = [len(embeddings)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "      pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)\n",
    "class_counts = np.array(labels).sum(axis=0)\n",
    "pos_weights = calculate_pos_weights(class_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1476691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 76., 118., 151.,  74.,  74.,  76., 151.,  95., 151., 151., 151., 151.,\n",
       "        151., 151., 150.,  83., 151.,  49., 151., 151.,  75., 123.,  74.,  49.,\n",
       "        137., 109., 151., 127.,  73., 150., 151., 145., 151., 151., 150., 151.,\n",
       "        148., 150., 151., 139., 151., 151., 151., 151., 151., 151., 151.,  93.,\n",
       "        151., 147., 150., 150., 151., 150., 151., 151., 151., 136., 151., 125.,\n",
       "        151.,  83., 151., 151., 151., 151.,  56., 147., 151., 151., 151., 151.,\n",
       "        151., 151., 151., 151., 145.,  73.,  92., 151., 151., 151., 151., 151.,\n",
       "        151., 117., 103., 151., 151., 151.,  92., 151., 151., 151., 131., 151.,\n",
       "        151., 151., 151., 140., 151., 151.,  74., 237., 151., 151.,  75.,  75.,\n",
       "        137., 151.,  75., 151., 151., 151., 148., 151., 726., 150., 151.,  75.,\n",
       "        151., 147., 151., 151., 151., 151.,  82., 151., 151., 151., 245., 187.,\n",
       "        237., 151., 150., 151., 150., 151.,  79., 151., 151., 151., 151., 150.,\n",
       "        150., 168., 130., 151., 145., 151., 150., 897., 953., 151.,  95., 151.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db438e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "566cb11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 76., 118., 151.,  74.,  74.,  76., 151.,  95., 151., 151., 151., 151.,\n",
       "        151., 151., 150.,  83., 151.,  49., 151., 151.,  75., 123.,  74.,  49.,\n",
       "        137., 109., 151., 127.,  73., 150., 151., 145., 151., 151., 150., 151.,\n",
       "        148., 150., 151., 139., 151., 151., 151., 151., 151., 151., 151.,  93.,\n",
       "        151., 147., 150., 150., 151., 150., 151., 151., 151., 136., 151., 125.,\n",
       "        151.,  83., 151., 151., 151., 151.,  56., 147., 151., 151., 151., 151.,\n",
       "        151., 151., 151., 151., 145.,  73.,  92., 151., 151., 151., 151., 151.,\n",
       "        151., 117., 103., 151., 151., 151.,  92., 151., 151., 151., 131., 151.,\n",
       "        151., 151., 151., 140., 151., 151.,  74., 237., 151., 151.,  75.,  75.,\n",
       "        137., 151.,  75., 151., 151., 151., 148., 151., 726., 150., 151.,  75.,\n",
       "        151., 147., 151., 151., 151., 151.,  82., 151., 151., 151., 245., 187.,\n",
       "        237., 151., 150., 151., 150., 151.,  79., 151., 151., 151., 151., 150.,\n",
       "        150., 168., 130., 151., 145., 151., 150., 897., 953., 151.,  95., 151.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fc1f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "# Zip the lists together\n",
    "combined = list(zip(embeddings, labels))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Unzip the shuffled list\n",
    "embeddings, labels = zip(*combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7184dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f832c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classification_V0(nn.Module):\n",
    "    def __init__(self, input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob):\n",
    "        super(Classification_V0, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, first_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_hidden, second_hidden)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_hidden, last_hidden)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(last_hidden, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 256\n",
    "first_hidden = 128\n",
    "second_hidden = 64\n",
    "last_hidden = 32\n",
    "output_dim = 156\n",
    "dropout_prob = 0.25\n",
    "\n",
    "clf_model = Classification_V0(input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d9abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "batch_size = 128\n",
    "def data_generator(embeddings, labels, batch_size):\n",
    "    num_samples = len(embeddings)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_embeddings = embeddings[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        yield batch_embeddings, batch_labels\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(clf_model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.05)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad1b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0215303897857666,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3149740272826749\n",
      "Epoch 2/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021195650100708008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.021913375804529\n",
      "Epoch 3/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02084636688232422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8388587107280538\n",
      "Epoch 4/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02098846435546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7352866861659402\n",
      "Epoch 5/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021048545837402344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6644290486893469\n",
      "Epoch 6/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020895004272460938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6087506939401482\n",
      "Epoch 7/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020946979522705078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5660301675652865\n",
      "Epoch 8/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020905733108520508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5296237760692464\n",
      "Epoch 9/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020867347717285156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4997489556972701\n",
      "Epoch 10/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021107912063598633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4740738214818808\n",
      "Epoch 11/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020893096923828125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44973872071711474\n",
      "Epoch 12/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020897388458251953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4543307968269553\n",
      "Epoch 13/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02098536491394043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44504107542106663\n",
      "Epoch 14/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020992279052734375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44838656442338687\n",
      "Epoch 15/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020849943161010742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4431699686606257\n",
      "Epoch 16/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021065235137939453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44246620073299747\n",
      "Epoch 17/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020917892456054688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438472666862203\n",
      "Epoch 18/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020914077758789062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4356009977349442\n",
      "Epoch 19/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0211789608001709,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44132672742682494\n",
      "Epoch 20/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020809412002563477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.439559220049845\n",
      "Epoch 21/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02091693878173828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4377686638572908\n",
      "Epoch 22/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020920991897583008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4346164563471926\n",
      "Epoch 23/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02082347869873047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43674876045072164\n",
      "Epoch 24/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021008729934692383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4372187581340238\n",
      "Epoch 25/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020838260650634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43883912911505657\n",
      "Epoch 26/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020902156829833984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4376844991947516\n",
      "Epoch 27/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021849870681762695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43541167108701895\n",
      "Epoch 28/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020908594131469727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4366290713886693\n",
      "Epoch 29/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0209963321685791,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43081431085952526\n",
      "Epoch 30/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021085262298583984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4324952793183792\n",
      "Epoch 31/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020925283432006836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43603341777729065\n",
      "Epoch 32/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02093195915222168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43587495445346397\n",
      "Epoch 33/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020932912826538086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43377355214576746\n",
      "Epoch 34/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02090907096862793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4366417463261393\n",
      "Epoch 35/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0208284854888916,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4359408268057293\n",
      "Epoch 36/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02105545997619629,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4401087223195374\n",
      "Epoch 37/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020760059356689453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4351681392647194\n",
      "Epoch 38/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020830869674682617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43294547055387467\n",
      "Epoch 39/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02167510986328125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43672481129664414\n",
      "Epoch 40/40:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020869016647338867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43226689511681976\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 40\n",
    "epoch_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    \n",
    "    # Initialize data generator\n",
    "    generator = data_generator(embeddings, labels, batch_size)\n",
    "    train_loss = 0\n",
    "    # Iterate over batches\n",
    "    for batch_embeddings, batch_labels in tqdm(generator, desc=\"Training Batches\", leave=False):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert data to tensors\n",
    "\n",
    "        batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_labels_tensor = torch.tensor(batch_labels, dtype = torch.float32)\n",
    "        outputs = clf_model(batch_embeddings_tensor)\n",
    "        loss = criterion(outputs, batch_labels_tensor)\n",
    "#         print(loss)\n",
    "        train_loss+=loss.item()\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    epoch_loss.append(train_loss/(len(embeddings)/batch_size))\n",
    "    print(train_loss/(len(embeddings)/batch_size))\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac44af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/ibex/user/toibazd/InterPro_annotated_genomes_for_testing/'\n",
    "# one_hot_encoded_sentences_2 = {}\n",
    "\n",
    "# sentence_length = 40\n",
    "# sentence_per_IP = 50\n",
    "# selected_files = os.listdir(directory)\n",
    "\n",
    "# total_sentences = sum(len(sentences) for sentences in one_hot_encoded_sentences.values())\n",
    "\n",
    "# # Iterate over keys\n",
    "# for IP in tqdm(unique_defense):\n",
    "#     one_hot_encoded_sentences_2[IP] = []\n",
    "#     sentences_count=0\n",
    "    \n",
    "#     # Iterate over selected files\n",
    "#     for filename in selected_files:\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "\n",
    "#         with open(filepath, 'r') as file:\n",
    "#             content = file.read()\n",
    "#             words = content.strip().split()\n",
    "\n",
    "#             # Check if the key is in the file\n",
    "#             for i in range(19, len(words)-20):\n",
    "#                 # Shuffle the indices of the words containing the key\n",
    "#                 if IP in data_dict[words[i]]:\n",
    "#                     if len(words) - i >= 21:\n",
    "#                         sentence = \" \".join(words[i - 19:i + sentence_length - 19])\n",
    "#                         one_hot_encoded_sentences_2[IP].append(sentence)\n",
    "#                         sentences_count += 1\n",
    "#                         if sentences_count>=sentence_per_IP:\n",
    "#                             break\n",
    "#         if sentences_count>=sentence_per_IP:\n",
    "#             break\n",
    "#     print(sentences_count)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7873eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in one_hot_encoded_sentences_2.items():\n",
    "#     print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5a2eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('BERT_sanity_check_secretion_DNN_senteces_testing.json', 'w') as f:\n",
    "#     json.dump(one_hot_encoded_sentences_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0aae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT_sanity_check_secretion_DNN_senteces_testing.json', \"r\") as f:\n",
    "    test_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ab316ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = {key: value for key, value in test_sentences.items() if value}\n",
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3e213bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = test_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a93cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7260"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d499e52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016710758209228516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 57,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a661679315464b5d8d86e44f9b99f506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bertviz import model_view\n",
    "\n",
    "batch_size = 128 # Define your batch size\n",
    "# model.cuda()\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "    # Convert lists to tensors and move to device\n",
    "    try:\n",
    "        input_ids = torch.tensor(input_ids_list)\n",
    "    except:\n",
    "        for ins in input_ids_list:\n",
    "            if len(ins)!=42:\n",
    "                print(len(ins))\n",
    "                print(ins)\n",
    "    attention_mask = torch.tensor(attention_mask_list)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True, output_attentions = True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    attentions = outputs.attentions[-1]\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]  # Extract the 20th token's hidden state\n",
    "#     for i in range(len(batch_sentences)):\n",
    "#         if i < 20:\n",
    "#             att = []\n",
    "#             extracted_tensor = attentions[i, :, :, :]\n",
    "#             extracted_tensor = extracted_tensor.unsqueeze(0)\n",
    "#             print(extracted_tensor.shape)\n",
    "#             att.append(extracted_tensor)\n",
    "\n",
    "#             tokens = \"[CLS] \"+tokenizer.decode(input_ids_list[i])+\" [SEP]\"\n",
    "#             tokens = tokens.split(\" \")\n",
    "#             model_view(att, tokens)\n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        test_embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        test_labels.append(one_hot_encoded_dict[indicator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00089282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WP_072018053 WP_072018053 WP_072018053 WP_072018053'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,12,12,12,12,\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b5d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6194248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_V0(\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=32, out_features=156, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d150c202",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_generator\u001b[49m(test_embeddings, test_labels, batch_size)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "generator = data_generator(test_embeddings, test_labels, batch_size)\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "for batch_embeddings, batch_labels in tqdm(generator, desc=\"Evaluation Batches\", leave=False):\n",
    "    batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "    batch_labels = np.array(batch_labels)\n",
    "    logits = clf_model(batch_embeddings_tensor)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "    thresholded_predictions = (predictions > 0.9).float()\n",
    "    all_predictions.append(thresholded_predictions.detach().numpy())\n",
    "    all_labels.append(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb88b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mall_labels\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "len(all_labels[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b4f0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_predictions\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "print(all_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe31ad51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_labels\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "print(all_labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a17e99d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Concatenate predictions and labels across all batches\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mconcatenate(all_predictions)\n\u001b[1;32m      3\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concatenate predictions and labels across all batches\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fb58693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7260, 156)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "333465a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "cl_report = multilabel_confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Classification report:\")\n",
    "print(len(cl_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b75b6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7079   82]\n",
      " [  42   57]]\n"
     ]
    }
   ],
   "source": [
    "print(cl_report[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bb7d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predictions, zero_division=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ecbf3a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139., 107., 177., 108.,  63., 150.,  65., 119., 203.,  62.,  37.,\n",
       "        72.,  44.,  46.,  73.,  91.,  45.,  92.,  71.,  79., 240., 160.,\n",
       "       178., 162.,  74.,  64., 100., 181., 175., 151.,  62.,  51., 133.,\n",
       "       155.,  71., 112.,  77., 190.,  69.,  83., 107.,  43.,  67.,  73.,\n",
       "        82.,  94.,  54., 181., 173., 136., 109.,  99., 112., 117., 202.,\n",
       "        50.,  32.,  49.,  60.,  53., 137., 109.,  86.,  37., 129.,  48.,\n",
       "       142., 103.,  54.,  68.,  67.,  76., 157.,  27.,  38., 101., 115.,\n",
       "       164., 136.,  90.,  97., 109., 128., 101., 110., 144.,  77.,  37.,\n",
       "        88.,  45., 103.,  63.,  64.,  55.,  92.,  63.,  83., 168., 130.,\n",
       "       148., 118., 105., 172.,  57., 106., 104., 129., 149.,  70.,  58.,\n",
       "       111.,  83.,  50.,  50., 116., 103.,  28.,  51., 119., 145., 112.,\n",
       "       106., 112.,  62.,  48., 223., 151.,  51.,  40., 128.,  74.,  52.,\n",
       "        34.,  59.,  69.,  50.,  51.,  58., 128.,  89.,  84., 111., 117.,\n",
       "       102.,  73.,  80.,  64., 168., 116.,  77., 214.,  12.,   8.,  37.,\n",
       "       137.,  95.], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "692d99ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.58      0.48        99\n",
      "           1       0.27      0.51      0.35        57\n",
      "           2       0.26      0.92      0.41        50\n",
      "           3       0.61      0.66      0.63       100\n",
      "           4       0.83      0.52      0.64       100\n",
      "           5       0.50      0.75      0.60       100\n",
      "           6       0.20      0.26      0.23        50\n",
      "           7       0.52      0.83      0.64        75\n",
      "           8       0.11      0.44      0.17        50\n",
      "           9       0.79      0.98      0.88        50\n",
      "          10       0.19      0.14      0.16        50\n",
      "          11       0.68      0.98      0.80        50\n",
      "          12       1.00      1.00      1.00        44\n",
      "          13       0.87      1.00      0.93        40\n",
      "          14       0.67      0.98      0.80        50\n",
      "          15       0.73      0.79      0.75        84\n",
      "          16       1.00      0.90      0.95        50\n",
      "          17       0.84      0.51      0.64       150\n",
      "          18       0.25      0.36      0.30        50\n",
      "          19       0.51      0.80      0.62        50\n",
      "          20       0.30      0.71      0.42       100\n",
      "          21       0.36      0.90      0.51        63\n",
      "          22       0.44      0.79      0.57       100\n",
      "          23       0.56      0.61      0.58       150\n",
      "          24       0.70      0.90      0.79        58\n",
      "          25       0.70      0.64      0.67        70\n",
      "          26       0.41      0.82      0.55        50\n",
      "          27       0.19      0.58      0.29        60\n",
      "          28       0.29      0.51      0.37       100\n",
      "          29       0.26      0.80      0.40        50\n",
      "          30       0.31      0.38      0.34        50\n",
      "          31       0.94      0.96      0.95        50\n",
      "          32       0.26      0.70      0.38        50\n",
      "          33       0.16      0.50      0.24        50\n",
      "          34       0.28      0.40      0.33        50\n",
      "          35       0.22      0.50      0.31        50\n",
      "          36       0.34      0.52      0.41        50\n",
      "          37       0.16      0.60      0.25        50\n",
      "          38       0.48      0.66      0.55        50\n",
      "          39       0.63      0.96      0.76        54\n",
      "          40       0.45      1.00      0.62        48\n",
      "          41       0.74      0.64      0.69        50\n",
      "          42       0.73      0.98      0.84        50\n",
      "          43       0.62      0.90      0.73        50\n",
      "          44       0.57      0.94      0.71        50\n",
      "          45       0.49      0.92      0.64        50\n",
      "          46       0.28      0.30      0.29        50\n",
      "          47       0.34      0.76      0.47        80\n",
      "          48       0.17      0.60      0.27        50\n",
      "          49       0.26      0.72      0.39        50\n",
      "          50       0.07      0.16      0.10        50\n",
      "          51       0.24      0.48      0.32        50\n",
      "          52       0.26      0.58      0.36        50\n",
      "          53       0.20      0.46      0.28        50\n",
      "          54       0.18      0.72      0.29        50\n",
      "          55       0.32      0.32      0.32        50\n",
      "          56       0.19      0.12      0.15        50\n",
      "          57       0.04      0.04      0.04        50\n",
      "          58       0.77      0.92      0.84        50\n",
      "          59       0.94      0.86      0.90        58\n",
      "          60       0.12      0.34      0.18        50\n",
      "          61       0.84      0.98      0.91        94\n",
      "          62       0.57      0.98      0.72        50\n",
      "          63       0.97      0.72      0.83        50\n",
      "          64       0.37      0.96      0.54        50\n",
      "          65       1.00      0.96      0.98        50\n",
      "          66       0.51      0.54      0.53       135\n",
      "          67       0.40      0.76      0.52        54\n",
      "          68       0.93      1.00      0.96        50\n",
      "          69       0.71      0.96      0.81        50\n",
      "          70       0.69      0.92      0.79        50\n",
      "          71       0.61      0.92      0.73        50\n",
      "          72       0.26      0.82      0.40        50\n",
      "          73       0.96      1.00      0.98        26\n",
      "          74       0.58      1.00      0.73        22\n",
      "          75       0.48      0.96      0.64        50\n",
      "          76       0.49      0.98      0.65        57\n",
      "          77       0.43      0.71      0.53        98\n",
      "          78       0.61      1.00      0.76        83\n",
      "          79       0.51      0.92      0.66        50\n",
      "          80       0.49      0.96      0.65        50\n",
      "          81       0.44      0.96      0.60        50\n",
      "          82       0.38      0.96      0.54        50\n",
      "          83       0.48      0.96      0.64        50\n",
      "          84       0.45      1.00      0.62        50\n",
      "          85       0.47      1.00      0.64        68\n",
      "          86       0.75      0.83      0.79        70\n",
      "          87       0.57      0.42      0.48        50\n",
      "          88       0.38      0.66      0.48        50\n",
      "          89       0.96      0.86      0.91        50\n",
      "          90       0.71      0.92      0.80        79\n",
      "          91       0.79      1.00      0.88        50\n",
      "          92       0.75      0.96      0.84        50\n",
      "          93       0.89      0.98      0.93        50\n",
      "          94       0.27      0.44      0.34        57\n",
      "          95       0.16      0.20      0.18        50\n",
      "          96       0.25      0.42      0.32        50\n",
      "          97       0.15      0.50      0.23        50\n",
      "          98       0.28      0.72      0.40        50\n",
      "          99       0.29      0.81      0.43        53\n",
      "         100       0.17      0.40      0.24        50\n",
      "         101       0.34      0.72      0.46        50\n",
      "         102       0.26      0.46      0.33        97\n",
      "         103       0.14      1.00      0.25         8\n",
      "         104       0.36      0.76      0.49        50\n",
      "         105       0.43      0.90      0.58        50\n",
      "         106       0.71      0.92      0.80       100\n",
      "         107       0.66      0.99      0.80       100\n",
      "         108       0.11      0.16      0.13        50\n",
      "         109       0.50      0.58      0.54        50\n",
      "         110       0.88      0.98      0.93       100\n",
      "         111       0.41      0.68      0.51        50\n",
      "         112       0.70      0.70      0.70        50\n",
      "         113       1.00      1.00      1.00        50\n",
      "         114       0.38      0.88      0.53        50\n",
      "         115       0.22      1.00      0.37        23\n",
      "         116       0.04      1.00      0.07         1\n",
      "         117       0.65      0.66      0.65        50\n",
      "         118       0.29      0.70      0.41        50\n",
      "         119       0.69      1.00      0.82       100\n",
      "         120       0.32      0.72      0.44        50\n",
      "         121       0.34      0.72      0.46        50\n",
      "         122       0.45      1.00      0.62        50\n",
      "         123       0.65      0.80      0.71        50\n",
      "         124       0.96      0.92      0.94        50\n",
      "         125       0.18      0.82      0.30        50\n",
      "         126       0.38      0.64      0.48        91\n",
      "         127       0.59      0.60      0.59        50\n",
      "         128       0.42      0.34      0.38        50\n",
      "         129       0.18      0.46      0.26        50\n",
      "         130       0.15      1.00      0.26        11\n",
      "         131       0.25      1.00      0.40        13\n",
      "         132       0.50      1.00      0.67        17\n",
      "         133       0.85      1.00      0.92        50\n",
      "         134       0.55      1.00      0.71        38\n",
      "         135       0.66      0.66      0.66        50\n",
      "         136       0.76      0.74      0.75        53\n",
      "         137       0.43      1.00      0.60        25\n",
      "         138       0.72      0.93      0.81        99\n",
      "         139       0.42      0.74      0.53        50\n",
      "         140       0.39      0.92      0.55        36\n",
      "         141       0.41      0.94      0.57        48\n",
      "         142       0.32      0.76      0.46        50\n",
      "         143       0.43      0.94      0.59        47\n",
      "         144       0.18      1.00      0.30        13\n",
      "         145       0.21      1.00      0.35        17\n",
      "         146       0.69      0.85      0.76        52\n",
      "         147       0.26      0.88      0.40        50\n",
      "         148       0.46      1.00      0.63        53\n",
      "         149       0.61      0.94      0.74        50\n",
      "         150       0.18      0.78      0.30        50\n",
      "         151       0.58      1.00      0.74         7\n",
      "         152       0.88      1.00      0.93         7\n",
      "         153       0.49      0.95      0.64        19\n",
      "         154       0.55      0.93      0.69        81\n",
      "         155       0.53      1.00      0.69        50\n",
      "\n",
      "   micro avg       0.43      0.75      0.54      8642\n",
      "   macro avg       0.48      0.76      0.56      8642\n",
      "weighted avg       0.50      0.75      0.58      8642\n",
      " samples avg       0.56      0.73      0.54      8642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a64d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enc.classes_)[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e153aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "num_classes = 83\n",
    "# Compute precision, recall, and thresholds for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "thresholds = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "for i in range(num_classes):  # num_classes is the number of classes\n",
    "    precision[i], recall[i], thresholds[i] = precision_recall_curve(all_labels[:, i], all_predictions[:, i])\n",
    "    average_precision[i] = average_precision_score(all_labels[:, i], all_predictions[:, i])\n",
    "\n",
    "# Compute micro-average precision-recall curve and AUC\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(all_labels.ravel(), all_predictions.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(all_labels, all_predictions, average=\"micro\")\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_predictions[:, i])\n",
    "    roc_auc[i] = roc_auc_score(all_labels[:, i], all_predictions[:, i])\n",
    "\n",
    "# Compute micro-average ROC curve and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_predictions.ravel())\n",
    "roc_auc[\"micro\"] = roc_auc_score(all_labels, all_predictions, average=\"micro\")\n",
    "\n",
    "# Split classes into groups of 10\n",
    "class_groups = [list(range(i, min(i + 10, num_classes))) for i in range(0, num_classes, 10)]\n",
    "\n",
    "# Plot Precision-Recall and ROC curves for each group\n",
    "for group in class_groups:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.step(recall['micro'], precision['micro'], where='post', label='Micro-average Precision-Recall curve (AUPR = {0:0.2f})'\n",
    "                 ''.format(average_precision[\"micro\"]))\n",
    "    for i in group:\n",
    "        plt.step(recall[i], precision[i], where='post', label='Precision-recall curve of class {0} (AUPR = {1:0.2f})'\n",
    "                 ''.format(i, average_precision[i]))\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve (Classes {})'.format(group))\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr['micro'], tpr['micro'], label='Micro-average ROC curve (AUC = {0:0.2f})'\n",
    "                 ''.format(roc_auc[\"micro\"]))\n",
    "    for i in group:\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (AUC = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve (Classes {})'.format(group))\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cbbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
