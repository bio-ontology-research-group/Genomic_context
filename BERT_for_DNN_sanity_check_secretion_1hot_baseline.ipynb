{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c622ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 290.74 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.available / (1024.0 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afee737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"WordLevel_tokenizer_trained_InterPro.json\"\n",
    "tokenizer = tokenizer.from_file(tokenizer_path)\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bef36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242995ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2966, 754, 2545, 196, 9231, 2817, 7418, 2526, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode(\"WP_265490204 WP_206642677 WP_053312998 WP_251959347 WP_000076573 WP_227526754 WP_218401808 WP_106925592\")\n",
    "test.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5c8709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secretion_IP.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "defense_ips = []\n",
    "directory = \"/home/toibazd/Secretion_InterPros/\"\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    file_path = os.path.join(directory, file)\n",
    "    with open(file_path, 'r', newline='') as infile:\n",
    "        reader = csv.reader(infile, delimiter = \"\\t\")\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            ip = row[0]\n",
    "            defense_ips.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679dec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secretion IPs number:  164\n"
     ]
    }
   ],
   "source": [
    "print(\"Secretion IPs number: \", len(defense_ips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ba9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005623340606689453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5905e731f12c43928956f4acfdca6243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data_dict = defaultdict(list)\n",
    "\n",
    "with open(\"/home/toibazd/Prot2IP.tsv\", \"r\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter = \"\\t\")\n",
    "    for row in tqdm(reader):\n",
    "        key = row[0].split(\"prot_\")[1].split(\".\")[0]\n",
    "        iprs = eval(row[1])\n",
    "\n",
    "        # Save only if there are filtered InterPro IDs\n",
    "        for ip in iprs:\n",
    "            if ip in defense_ips:\n",
    "                data_dict[key].append(ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334d007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_defense = set()\n",
    "\n",
    "# Iterate through each value list in the dictionary and add its elements to the set\n",
    "for value_list in data_dict.values():\n",
    "    unique_defense.update(value_list)\n",
    "\n",
    "# Convert the set to a list if needed\n",
    "unique_defense = list(unique_defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b651fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f471e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "enc = MultiLabelBinarizer()\n",
    "one_hot_encoded = enc.fit_transform(data_dict.values())\n",
    "one_hot_encoded_dict = {key: value for key, value in zip(data_dict.keys(), one_hot_encoded)}\n",
    "\n",
    "print(len(one_hot_encoded_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7464990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4161, 156)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51e75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# directory = '/ibex/user/toibazd/InterPro_annotated_genomes/'\n",
    "# one_hot_encoded_sentences = {}\n",
    "\n",
    "# sentence_length = 40\n",
    "# sentences_per_IP = 100\n",
    "\n",
    "# # Set random seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "# # Randomly choose 1000 files with seed 42\n",
    "# selected_files = os.listdir(directory)\n",
    "\n",
    "\n",
    "# # Define a function to process a file\n",
    "# def process_file(filename, IP):\n",
    "#     sentences = []\n",
    "\n",
    "#     filepath = os.path.join(directory, filename)\n",
    "\n",
    "#     with open(filepath, 'r') as file:\n",
    "#         content = file.read()\n",
    "#         words = content.strip().split()\n",
    "\n",
    "#         # Check if the key is in the file\n",
    "#         for i in range(19, len(words)-20):\n",
    "#             # Shuffle the indices of the words containing the key\n",
    "#             if IP in data_dict[words[i]]:\n",
    "#                 if len(words) - i >= 21:\n",
    "#                     sentence = \" \".join(words[i - 19:i + sentence_length - 19])\n",
    "#                     sentences.append(sentence)\n",
    "#     return sentences\n",
    "\n",
    "\n",
    "# # Iterate over keys\n",
    "# for IP in tqdm(unique_defense):\n",
    "#     one_hot_encoded_sentences[IP] = []\n",
    "#     sentences_count = 0\n",
    "\n",
    "#     # Use ThreadPoolExecutor for concurrent processing\n",
    "#     with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "#         futures = [executor.submit(process_file, filename, IP) for filename in selected_files]\n",
    "#         for future in futures:\n",
    "#             sentences = future.result()\n",
    "#             one_hot_encoded_sentences[IP].extend(sentences)\n",
    "#             sentences_count += len(sentences)\n",
    "#             if sentences_count >= sentences_per_IP:\n",
    "#                 break\n",
    "\n",
    "#     # Break if the required number of sentences per key is reached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abea8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, values in one_hot_encoded_sentences.items():\n",
    "#     print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a55b4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('BERT_sanity_check_defense_DNN_senteces.json', 'w') as f:\n",
    "#     json.dump(one_hot_encoded_sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeeb70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('BERT_sanity_check_secretion_DNN_senteces.json', \"r\") as f:\n",
    "    one_hot_encoded_sentences = json.load(f)\n",
    "    \n",
    "    \n",
    "with open('BERT_sanity_check_secretion_DNN_senteces_testing.json', \"r\") as f:\n",
    "    test_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1149a6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPR010263 100\n",
      "IPR048130 101\n",
      "IPR006533 102\n",
      "IPR032389 100\n",
      "IPR025955 100\n",
      "IPR012842 100\n",
      "IPR001639 100\n",
      "IPR018920 100\n",
      "IPR017847 102\n",
      "IPR009371 100\n",
      "IPR035576 100\n",
      "IPR013391 100\n",
      "IPR002010 102\n",
      "IPR010586 100\n",
      "IPR017737 100\n",
      "IPR039366 100\n",
      "IPR003895 100\n",
      "IPR010130 101\n",
      "IPR034026 100\n",
      "IPR027282 100\n",
      "IPR009211 100\n",
      "IPR047659 90\n",
      "IPR009863 100\n",
      "IPR003283 100\n",
      "IPR013369 100\n",
      "IPR009929 100\n",
      "IPR021545 100\n",
      "IPR005714 100\n",
      "IPR008312 102\n",
      "IPR034756 100\n",
      "IPR011850 100\n",
      "IPR031758 101\n",
      "IPR025292 100\n",
      "IPR008514 100\n",
      "IPR023835 100\n",
      "IPR010290 100\n",
      "IPR021368 100\n",
      "IPR027628 100\n",
      "IPR022250 100\n",
      "IPR023834 103\n",
      "IPR005696 100\n",
      "IPR049928 100\n",
      "IPR022792 100\n",
      "IPR047695 100\n",
      "IPR004683 100\n",
      "IPR010128 103\n",
      "IPR010129 101\n",
      "IPR026264 100\n",
      "IPR023787 100\n",
      "IPR017739 100\n",
      "IPR019861 110\n",
      "IPR011841 100\n",
      "IPR017740 100\n",
      "IPR018893 100\n",
      "IPR007606 104\n",
      "IPR006304 101\n",
      "IPR017738 100\n",
      "IPR013363 100\n",
      "IPR049875 100\n",
      "IPR049801 16\n",
      "IPR013365 100\n",
      "IPR005838 101\n",
      "IPR005415 100\n",
      "IPR010132 100\n",
      "IPR043993 101\n",
      "IPR017750 100\n",
      "IPR017735 100\n",
      "IPR021055 100\n",
      "IPR005628 100\n",
      "IPR013388 100\n",
      "IPR017033 100\n",
      "IPR007812 100\n",
      "IPR012672 100\n",
      "IPR035177 100\n",
      "IPR032681 100\n",
      "IPR013380 100\n",
      "IPR009483 100\n",
      "IPR017734 100\n",
      "IPR009335 100\n",
      "IPR010272 100\n",
      "IPR047799 100\n",
      "IPR005773 101\n",
      "IPR004355 100\n",
      "IPR005416 100\n",
      "IPR010052 100\n",
      "IPR006307 100\n",
      "IPR010269 100\n",
      "IPR007795 101\n",
      "IPR010054 100\n",
      "IPR048928 17\n",
      "IPR022275 21\n",
      "IPR009510 100\n",
      "IPR003282 100\n",
      "IPR012843 100\n",
      "IPR006135 101\n",
      "IPR010310 111\n",
      "IPR010055 100\n",
      "IPR032032 100\n",
      "IPR022073 102\n",
      "IPR005498 100\n",
      "IPR013349 100\n",
      "IPR030925 81\n",
      "IPR018581 64\n",
      "IPR021477 100\n",
      "IPR012670 100\n",
      "IPR007039 100\n",
      "IPR022797 100\n",
      "IPR013095 100\n",
      "IPR021123 100\n",
      "IPR039449 101\n",
      "IPR013392 100\n",
      "IPR006302 100\n",
      "IPR003522 100\n",
      "IPR013356 100\n",
      "IPR002416 100\n",
      "IPR004357 100\n",
      "IPR017731 100\n",
      "IPR016379 100\n",
      "IPR007690 100\n",
      "IPR012673 100\n",
      "IPR006707 101\n",
      "IPR006306 100\n",
      "IPR009502 100\n",
      "IPR001712 101\n",
      "IPR007792 100\n",
      "IPR016502 100\n",
      "IPR014117 100\n",
      "IPR022536 101\n",
      "IPR003537 100\n",
      "IPR023840 100\n",
      "IPR014155 100\n",
      "IPR018778 100\n",
      "IPR013394 100\n",
      "IPR019029 100\n",
      "IPR049848 100\n",
      "IPR013405 100\n",
      "IPR013390 100\n",
      "IPR001172 100\n",
      "IPR010732 100\n",
      "IPR013348 100\n",
      "IPR016684 100\n",
      "IPR030924 62\n",
      "IPR010437 100\n",
      "IPR003688 100\n",
      "IPR000983 100\n",
      "IPR014158 100\n",
      "IPR031682 100\n",
      "IPR048018 100\n",
      "IPR013393 100\n",
      "IPR013385 100\n",
      "IPR013387 100\n",
      "IPR014575 100\n",
      "IPR013353 100\n",
      "IPR025562 100\n",
      "IPR048081 100\n",
      "IPR030927 64\n"
     ]
    }
   ],
   "source": [
    "for key, value in one_hot_encoded_sentences.items():\n",
    "    print(key, end=\" \")\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deeb72f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of one_hot_encoded sentences items  156\n",
      "Len of one_hot_encoded_sentences values  156\n",
      "Len of all sentences in matching strings:  15270\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_sentences = {key: value for key, value in one_hot_encoded_sentences.items() if value}\n",
    "print(\"Len of one_hot_encoded sentences items \",len(one_hot_encoded_sentences))\n",
    "\n",
    "matching_string = one_hot_encoded_sentences.values()\n",
    "print(\"Len of one_hot_encoded_sentences values \", len(matching_string))\n",
    "\n",
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "print(\"Len of all sentences in matching strings: \", len(matching_string))\n",
    "\n",
    "train_words_list = [sentence.split() for sentence in matching_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9c37c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of test sentences items 156\n",
      "Len of test sentences values 156\n",
      "Len of test sentences in matching strings:  7260\n"
     ]
    }
   ],
   "source": [
    "test_sentences = {key: value for key, value in test_sentences.items() if value}\n",
    "print(\"Len of test sentences items\", len(test_sentences))\n",
    "test_matching_string = test_sentences.values()\n",
    "print(\"Len of test sentences values\", len(test_matching_string))\n",
    "test_matching_string = [item for sublist in test_matching_string for item in sublist]\n",
    "print(\"Len of test sentences in matching strings: \", len(test_matching_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5709f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_words_list = [sentence.split() for sentence in test_matching_string]\n",
    "\n",
    "fit_word_list = train_words_list+test_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c1c4fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15270\n"
     ]
    }
   ],
   "source": [
    "count= 0\n",
    "for string in train_words_list:\n",
    "    if not string[19] in data_dict.keys():\n",
    "        print(\"False\")\n",
    "    else:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45e9247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15270, 76641)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "mlb.fit(fit_word_list)\n",
    "\n",
    "\n",
    "one_hot_contexts = mlb.transform(train_words_list)\n",
    "embeddings = one_hot_contexts.toarray()\n",
    "one_hot_contexts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9262a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b43fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-25 15:02:25,114] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(544998, 256, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (token_type_embeddings): Embedding(2, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): None\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Check if CUDA is available and choose device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"/home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final\"\n",
    "\n",
    "model = BertModel.from_pretrained(model_path).cuda()\n",
    "model.pooler = None\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "978dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156,)\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_encoded[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c35dd100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017815351486206055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 120,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2745e3b6144e4997308450dcb0273b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128 # Define your batch size\n",
    "model.cuda()\n",
    "ems = []\n",
    "labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "\n",
    "    # Convert lists to tensors and move to device\n",
    "    input_ids = torch.tensor(input_ids_list).cuda()\n",
    "    attention_mask = torch.tensor(attention_mask_list).cuda()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]  # Extract the 20th token's hidden state\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        ems.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        labels.append(one_hot_encoded_dict[indicator])\n",
    "\n",
    "# Ensure order in embeddings matches order in labels\n",
    "\n",
    "# Now embeddings and labels are stored on the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cad879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    \n",
    "    neg_counts = [len(embeddings)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "      pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)\n",
    "class_counts = np.array(labels).sum(axis=0)\n",
    "pos_weights = calculate_pos_weights(class_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1476691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 76., 118., 151.,  74.,  74.,  76., 151.,  95., 151., 151., 151., 151.,\n",
       "        151., 151., 150.,  83., 151.,  49., 151., 151.,  75., 123.,  74.,  49.,\n",
       "        137., 109., 151., 127.,  73., 150., 151., 145., 151., 151., 150., 151.,\n",
       "        148., 150., 151., 139., 151., 151., 151., 151., 151., 151., 151.,  93.,\n",
       "        151., 147., 150., 150., 151., 150., 151., 151., 151., 136., 151., 125.,\n",
       "        151.,  83., 151., 151., 151., 151.,  56., 147., 151., 151., 151., 151.,\n",
       "        151., 151., 151., 151., 145.,  73.,  92., 151., 151., 151., 151., 151.,\n",
       "        151., 117., 103., 151., 151., 151.,  92., 151., 151., 151., 131., 151.,\n",
       "        151., 151., 151., 140., 151., 151.,  74., 237., 151., 151.,  75.,  75.,\n",
       "        137., 151.,  75., 151., 151., 151., 148., 151., 726., 150., 151.,  75.,\n",
       "        151., 147., 151., 151., 151., 151.,  82., 151., 151., 151., 245., 187.,\n",
       "        237., 151., 150., 151., 150., 151.,  79., 151., 151., 151., 151., 150.,\n",
       "        150., 168., 130., 151., 145., 151., 150., 897., 953., 151.,  95., 151.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc1f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "# Zip the lists together\n",
    "combined = list(zip(embeddings, labels))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Unzip the shuffled list\n",
    "embeddings, labels = zip(*combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7184dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f832c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classification_V0(nn.Module):\n",
    "    def __init__(self, input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob):\n",
    "        super(Classification_V0, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, first_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_hidden, second_hidden)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_hidden, last_hidden)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(last_hidden, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 76641\n",
    "first_hidden = 256\n",
    "second_hidden = 128\n",
    "last_hidden = 64\n",
    "output_dim = 156\n",
    "dropout_prob = 0.25\n",
    "\n",
    "clf_model = Classification_V0(input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d9abc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_V0(\n",
       "  (fc1): Linear(in_features=76641, out_features=256, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=64, out_features=156, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "batch_size = 256\n",
    "def data_generator(embeddings, labels, batch_size):\n",
    "    num_samples = len(embeddings)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_embeddings = embeddings[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        yield batch_embeddings, batch_labels\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(clf_model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.1)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "clf_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad1b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02186727523803711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2158480431257546\n",
      "Epoch 2/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021437644958496094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5994016596126494\n",
      "Epoch 3/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021408557891845703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3549218982828936\n",
      "Epoch 4/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02176642417907715,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27777717005761526\n",
      "Epoch 5/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02132439613342285,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23625494076991752\n",
      "Epoch 6/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02132415771484375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21064347352713014\n",
      "Epoch 7/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021317005157470703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19177897215357934\n",
      "Epoch 8/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021423816680908203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1776157831318174\n",
      "Epoch 9/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021328210830688477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1638950645181972\n",
      "Epoch 10/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021406888961791992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15574549392070658\n",
      "Epoch 11/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02157425880432129,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14869898163421372\n",
      "Epoch 12/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021712064743041992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.144172163577976\n",
      "Epoch 13/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021283388137817383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1404149479544389\n",
      "Epoch 14/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021096229553222656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1403341749249991\n",
      "Epoch 15/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02130913734436035,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13856562968555744\n",
      "Epoch 16/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02104949951171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13710170700882648\n",
      "Epoch 17/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02107691764831543,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13510790739328002\n",
      "Epoch 18/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021563053131103516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13468301569470878\n",
      "Epoch 19/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021288156509399414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13305397221053747\n",
      "Epoch 20/20:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021047115325927734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13249578045018764\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 20\n",
    "epoch_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    \n",
    "    # Initialize data generator\n",
    "    generator = data_generator(embeddings, labels, batch_size)\n",
    "    train_loss = 0\n",
    "    # Iterate over batches\n",
    "    for batch_embeddings, batch_labels in tqdm(generator, desc=\"Training Batches\", leave=False):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        batch_embeddings = np.array(batch_embeddings)\n",
    "        batch_embeddings_tensor = torch.tensor(batch_embeddings, dtype= torch.float32).cuda()\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_labels_tensor = torch.tensor(batch_labels, dtype = torch.float32)\n",
    "        \n",
    "        outputs = clf_model(batch_embeddings_tensor)\n",
    "        loss = criterion(outputs.cpu(), batch_labels_tensor)\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    epoch_loss.append(train_loss/(len(embeddings)/batch_size))\n",
    "    print(train_loss/(len(embeddings)/batch_size))\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac44af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/ibex/user/toibazd/InterPro_annotated_genomes_for_testing/'\n",
    "# one_hot_encoded_sentences_2 = {}\n",
    "\n",
    "# sentence_length = 40\n",
    "# sentence_per_IP = 50\n",
    "# selected_files = os.listdir(directory)\n",
    "\n",
    "# total_sentences = sum(len(sentences) for sentences in one_hot_encoded_sentences.values())\n",
    "\n",
    "# # Iterate over keys\n",
    "# for IP in tqdm(unique_defense):\n",
    "#     one_hot_encoded_sentences_2[IP] = []\n",
    "#     sentences_count=0\n",
    "    \n",
    "#     # Iterate over selected files\n",
    "#     for filename in selected_files:\n",
    "#         filepath = os.path.join(directory, filename)\n",
    "\n",
    "#         with open(filepath, 'r') as file:\n",
    "#             content = file.read()\n",
    "#             words = content.strip().split()\n",
    "\n",
    "#             # Check if the key is in the file\n",
    "#             for i in range(19, len(words)-20):\n",
    "#                 # Shuffle the indices of the words containing the key\n",
    "#                 if IP in data_dict[words[i]]:\n",
    "#                     if len(words) - i >= 21:\n",
    "#                         sentence = \" \".join(words[i - 19:i + sentence_length - 19])\n",
    "#                         one_hot_encoded_sentences_2[IP].append(sentence)\n",
    "#                         sentences_count += 1\n",
    "#                         if sentences_count>=sentence_per_IP:\n",
    "#                             break\n",
    "#         if sentences_count>=sentence_per_IP:\n",
    "#             break\n",
    "#     print(sentences_count)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7873eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in one_hot_encoded_sentences_2.items():\n",
    "#     print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5a2eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('BERT_sanity_check_defense_DNN_senteces_testing.json', 'w') as f:\n",
    "#     json.dump(one_hot_encoded_sentences_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0aae8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "with open('BERT_sanity_check_secretion_DNN_senteces_testing.json', \"r\") as f:\n",
    "    test_sentences = json.load(f)\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a93cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7260"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = {key: value for key, value in test_sentences.items() if value}\n",
    "print(len(test_sentences))\n",
    "test_matching_string = test_sentences.values()\n",
    "len(test_matching_string)\n",
    "test_matching_string = [item for sublist in test_matching_string for item in sublist]\n",
    "len(test_matching_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc8e268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7260, 76641)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "words_list = [sentence.split() for sentence in test_matching_string]\n",
    "one_hot_contexts = mlb.transform(words_list)\n",
    "embeddings = one_hot_contexts.toarray()\n",
    "one_hot_contexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cae8e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7260\n"
     ]
    }
   ],
   "source": [
    "count= 0\n",
    "for string in words_list:\n",
    "    if not string[19] in data_dict.keys():\n",
    "        print(\"False\")\n",
    "    else:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d499e52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017546653747558594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 57,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e2366b6c64214b73312aba747fb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bertviz import model_view\n",
    "\n",
    "batch_size = 128 # Define your batch size\n",
    "# model.cuda()\n",
    "test_ems = []\n",
    "test_labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(test_matching_string), batch_size)):\n",
    "    batch_sentences = test_matching_string[i:i+batch_size]\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "    # Convert lists to tensors and move to device\n",
    "    try:\n",
    "        input_ids = torch.tensor(input_ids_list)\n",
    "    except:\n",
    "        for ins in input_ids_list:\n",
    "            if len(ins)!=42:\n",
    "                print(len(ins))\n",
    "                print(ins)\n",
    "    attention_mask = torch.tensor(attention_mask_list)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True, output_attentions = True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    attentions = outputs.attentions[-1]\n",
    "    relevant_hidden_states = hidden_states[:, 20, :]  # Extract the 20th token's hidden state\n",
    "#     for i in range(len(batch_sentences)):\n",
    "#         if i < 20:\n",
    "#             att = []\n",
    "#             extracted_tensor = attentions[i, :, :, :]\n",
    "#             extracted_tensor = extracted_tensor.unsqueeze(0)\n",
    "#             print(extracted_tensor.shape)\n",
    "#             att.append(extracted_tensor)\n",
    "\n",
    "#             tokens = \"[CLS] \"+tokenizer.decode(input_ids_list[i])+\" [SEP]\"\n",
    "#             tokens = tokens.split(\" \")\n",
    "#             model_view(att, tokens)\n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        test_ems.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[19]\n",
    "        test_labels.append(one_hot_encoded_dict[indicator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00089282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WP_072018053 WP_072018053 WP_072018053 WP_072018053'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,12,12,12,12,\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b5d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6194248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_V0(\n",
       "  (fc1): Linear(in_features=76641, out_features=256, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=64, out_features=156, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model.eval()\n",
    "clf_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d150c202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021477937698364258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluation Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = data_generator(embeddings, test_labels, batch_size)\n",
    "# Iterate over batches\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "# Initialize lists to store predictions and labels across all batches\n",
    "# Iterate over batches\n",
    "count = 0\n",
    "for batch_embeddings, batch_labels in tqdm(generator, desc=\"Evaluation Batches\", leave=False):\n",
    "    batch_embeddings_tensor = torch.tensor(batch_embeddings, dtype= torch.float32)\n",
    "    batch_labels = np.array(batch_labels)\n",
    "    logits = clf_model(batch_embeddings_tensor)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "    thresholded_predictions = (predictions > 0.9).float()\n",
    "    all_predictions.append(thresholded_predictions.detach().numpy())\n",
    "    all_labels.append(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd80f04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2eb88b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0b4f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 156)\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe31ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 156)\n"
     ]
    }
   ],
   "source": [
    "print(all_labels[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a17e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate predictions and labels across all batches\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fb58693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7260, 156)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c72bd654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7260, 156)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "333465a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "cl_report = multilabel_confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Classification report:\")\n",
    "print(len(cl_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b75b6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6924  237]\n",
      " [  15   84]]\n"
     ]
    }
   ],
   "source": [
    "print(cl_report[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6bb7d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predictions, zero_division=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecbf3a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([321., 149., 163., 182., 348., 363., 380., 217., 177., 102.,  61.,\n",
       "       133.,  44.,  47.,  50., 173.,  72., 224., 315.,  53., 463., 252.,\n",
       "       333., 296., 214., 262., 263., 274.,  82., 251., 101.,  54., 264.,\n",
       "       123., 242., 304., 151., 134., 222., 118., 102., 129.,  50., 199.,\n",
       "       205., 160., 415., 337., 225.,  73., 120., 108.,  42., 272., 208.,\n",
       "       217.,  32.,  91., 151., 119., 259., 308., 380., 375., 206., 186.,\n",
       "       308., 164.,  55., 217., 184., 154., 310.,  26.,  47., 300., 465.,\n",
       "       260., 189., 193., 409., 394., 387., 392., 414., 208.,  97., 240.,\n",
       "       138.,  99., 168.,  79., 245.,  80., 148., 265., 167., 294., 117.,\n",
       "       193., 286.,  66.,  84.,  20., 178.,  46., 157., 195.,  56., 113.,\n",
       "       319., 165.,  70.,  69., 117.,  46.,   1.,  66., 110., 285.,  46.,\n",
       "       239., 169.,  98., 181., 136., 107., 121.,  32.,  64.,  15.,  16.,\n",
       "        18.,  86.,  38., 137.,  78.,  25., 156.,  64., 109.,  88.,  66.,\n",
       "        87.,  15.,  27., 121.,  46.,  58.,  50.,  65.,   7.,  11.,  19.,\n",
       "       366.,  51.], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "692d99ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.85      0.40        99\n",
      "           1       0.30      0.77      0.43        57\n",
      "           2       0.28      0.92      0.43        50\n",
      "           3       0.28      0.51      0.36       100\n",
      "           4       0.17      0.60      0.27       100\n",
      "           5       0.26      0.95      0.41       100\n",
      "           6       0.08      0.60      0.14        50\n",
      "           7       0.31      0.91      0.47        75\n",
      "           8       0.18      0.62      0.27        50\n",
      "           9       0.49      1.00      0.66        50\n",
      "          10       0.28      0.34      0.31        50\n",
      "          11       0.37      0.98      0.54        50\n",
      "          12       0.93      0.93      0.93        44\n",
      "          13       0.85      1.00      0.92        40\n",
      "          14       1.00      1.00      1.00        50\n",
      "          15       0.39      0.80      0.52        84\n",
      "          16       0.65      0.94      0.77        50\n",
      "          17       0.55      0.82      0.66       150\n",
      "          18       0.12      0.76      0.21        50\n",
      "          19       0.89      0.94      0.91        50\n",
      "          20       0.16      0.74      0.26       100\n",
      "          21       0.18      0.73      0.29        63\n",
      "          22       0.20      0.65      0.30       100\n",
      "          23       0.35      0.69      0.47       150\n",
      "          24       0.17      0.62      0.26        58\n",
      "          25       0.17      0.63      0.27        70\n",
      "          26       0.13      0.68      0.22        50\n",
      "          27       0.14      0.63      0.23        60\n",
      "          28       0.74      0.61      0.67       100\n",
      "          29       0.18      0.92      0.31        50\n",
      "          30       0.33      0.66      0.44        50\n",
      "          31       0.93      1.00      0.96        50\n",
      "          32       0.17      0.92      0.29        50\n",
      "          33       0.28      0.68      0.39        50\n",
      "          34       0.19      0.94      0.32        50\n",
      "          35       0.15      0.92      0.26        50\n",
      "          36       0.13      0.40      0.20        50\n",
      "          37       0.15      0.40      0.22        50\n",
      "          38       0.22      0.98      0.36        50\n",
      "          39       0.45      0.98      0.62        54\n",
      "          40       0.47      1.00      0.64        48\n",
      "          41       0.39      1.00      0.56        50\n",
      "          42       1.00      1.00      1.00        50\n",
      "          43       0.24      0.96      0.39        50\n",
      "          44       0.23      0.96      0.38        50\n",
      "          45       0.30      0.96      0.46        50\n",
      "          46       0.10      0.86      0.18        50\n",
      "          47       0.20      0.85      0.33        80\n",
      "          48       0.19      0.86      0.31        50\n",
      "          49       0.62      0.90      0.73        50\n",
      "          50       0.26      0.62      0.36        50\n",
      "          51       0.33      0.72      0.46        50\n",
      "          52       0.74      0.62      0.67        50\n",
      "          53       0.09      0.50      0.16        50\n",
      "          54       0.10      0.40      0.16        50\n",
      "          55       0.10      0.42      0.16        50\n",
      "          56       0.91      0.58      0.71        50\n",
      "          57       0.20      0.36      0.26        50\n",
      "          58       0.32      0.96      0.48        50\n",
      "          59       0.47      0.97      0.63        58\n",
      "          60       0.10      0.52      0.17        50\n",
      "          61       0.27      0.89      0.42        94\n",
      "          62       0.12      0.92      0.21        50\n",
      "          63       0.13      0.94      0.22        50\n",
      "          64       0.24      0.98      0.38        50\n",
      "          65       0.26      0.98      0.42        50\n",
      "          66       0.37      0.85      0.52       135\n",
      "          67       0.24      0.74      0.37        54\n",
      "          68       0.89      0.98      0.93        50\n",
      "          69       0.23      0.98      0.37        50\n",
      "          70       0.27      1.00      0.43        50\n",
      "          71       0.32      1.00      0.49        50\n",
      "          72       0.14      0.84      0.23        50\n",
      "          73       1.00      1.00      1.00        26\n",
      "          74       0.47      1.00      0.64        22\n",
      "          75       0.14      0.84      0.24        50\n",
      "          76       0.12      0.98      0.21        57\n",
      "          77       0.30      0.79      0.43        98\n",
      "          78       0.42      0.96      0.59        83\n",
      "          79       0.24      0.94      0.39        50\n",
      "          80       0.12      1.00      0.22        50\n",
      "          81       0.13      1.00      0.23        50\n",
      "          82       0.13      1.00      0.23        50\n",
      "          83       0.13      1.00      0.23        50\n",
      "          84       0.12      1.00      0.22        50\n",
      "          85       0.32      0.97      0.48        68\n",
      "          86       0.64      0.89      0.74        70\n",
      "          87       0.17      0.82      0.28        50\n",
      "          88       0.25      0.68      0.36        50\n",
      "          89       0.51      1.00      0.67        50\n",
      "          90       0.42      0.90      0.57        79\n",
      "          91       0.63      1.00      0.78        50\n",
      "          92       0.20      0.98      0.33        50\n",
      "          93       0.61      0.98      0.75        50\n",
      "          94       0.20      0.53      0.29        57\n",
      "          95       0.11      0.58      0.18        50\n",
      "          96       0.22      0.74      0.34        50\n",
      "          97       0.11      0.64      0.19        50\n",
      "          98       0.42      0.98      0.59        50\n",
      "          99       0.25      0.92      0.40        53\n",
      "         100       0.15      0.86      0.26        50\n",
      "         101       0.53      0.70      0.60        50\n",
      "         102       0.71      0.62      0.66        97\n",
      "         103       0.40      1.00      0.57         8\n",
      "         104       0.26      0.94      0.41        50\n",
      "         105       0.96      0.88      0.92        50\n",
      "         106       0.64      1.00      0.78       100\n",
      "         107       0.49      0.95      0.64       100\n",
      "         108       0.82      0.92      0.87        50\n",
      "         109       0.44      1.00      0.61        50\n",
      "         110       0.28      0.89      0.42       100\n",
      "         111       0.27      0.90      0.42        50\n",
      "         112       0.64      0.90      0.75        50\n",
      "         113       0.72      1.00      0.84        50\n",
      "         114       0.42      0.98      0.59        50\n",
      "         115       0.50      1.00      0.67        23\n",
      "         116       1.00      1.00      1.00         1\n",
      "         117       0.70      0.92      0.79        50\n",
      "         118       0.43      0.94      0.59        50\n",
      "         119       0.33      0.95      0.49       100\n",
      "         120       1.00      0.92      0.96        50\n",
      "         121       0.20      0.94      0.33        50\n",
      "         122       0.29      0.98      0.45        50\n",
      "         123       0.51      1.00      0.68        50\n",
      "         124       0.27      0.98      0.42        50\n",
      "         125       0.35      0.94      0.51        50\n",
      "         126       0.76      0.89      0.82        91\n",
      "         127       0.35      0.84      0.49        50\n",
      "         128       0.97      0.62      0.76        50\n",
      "         129       0.67      0.86      0.75        50\n",
      "         130       0.73      1.00      0.85        11\n",
      "         131       0.81      1.00      0.90        13\n",
      "         132       0.94      1.00      0.97        17\n",
      "         133       0.58      1.00      0.74        50\n",
      "         134       1.00      1.00      1.00        38\n",
      "         135       0.36      0.98      0.52        50\n",
      "         136       0.67      0.98      0.79        53\n",
      "         137       1.00      1.00      1.00        25\n",
      "         138       0.63      1.00      0.78        99\n",
      "         139       0.77      0.98      0.86        50\n",
      "         140       0.32      0.97      0.48        36\n",
      "         141       0.49      0.90      0.63        48\n",
      "         142       0.71      0.94      0.81        50\n",
      "         143       0.54      1.00      0.70        47\n",
      "         144       0.87      1.00      0.93        13\n",
      "         145       0.63      1.00      0.77        17\n",
      "         146       0.40      0.94      0.57        52\n",
      "         147       0.98      0.90      0.94        50\n",
      "         148       0.90      0.98      0.94        53\n",
      "         149       1.00      1.00      1.00        50\n",
      "         150       0.66      0.86      0.75        50\n",
      "         151       1.00      1.00      1.00         7\n",
      "         152       0.64      1.00      0.78         7\n",
      "         153       1.00      1.00      1.00        19\n",
      "         154       0.22      0.99      0.36        81\n",
      "         155       0.98      1.00      0.99        50\n",
      "\n",
      "   micro avg       0.28      0.85      0.43      8642\n",
      "   macro avg       0.44      0.87      0.54      8642\n",
      "weighted avg       0.41      0.85      0.51      8642\n",
      " samples avg       0.44      0.85      0.51      8642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a64d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enc.classes_)[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e153aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "num_classes = 83\n",
    "# Compute precision, recall, and thresholds for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "thresholds = dict()\n",
    "average_precision = dict()\n",
    "\n",
    "for i in range(num_classes):  # num_classes is the number of classes\n",
    "    precision[i], recall[i], thresholds[i] = precision_recall_curve(all_labels[:, i], all_predictions[:, i])\n",
    "    average_precision[i] = average_precision_score(all_labels[:, i], all_predictions[:, i])\n",
    "\n",
    "# Compute micro-average precision-recall curve and AUC\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(all_labels.ravel(), all_predictions.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(all_labels, all_predictions, average=\"micro\")\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_predictions[:, i])\n",
    "    roc_auc[i] = roc_auc_score(all_labels[:, i], all_predictions[:, i])\n",
    "\n",
    "# Compute micro-average ROC curve and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_predictions.ravel())\n",
    "roc_auc[\"micro\"] = roc_auc_score(all_labels, all_predictions, average=\"micro\")\n",
    "\n",
    "# Split classes into groups of 10\n",
    "class_groups = [list(range(i, min(i + 10, num_classes))) for i in range(0, num_classes, 10)]\n",
    "\n",
    "# Plot Precision-Recall and ROC curves for each group\n",
    "for group in class_groups:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.step(recall['micro'], precision['micro'], where='post', label='Micro-average Precision-Recall curve (AUPR = {0:0.2f})'\n",
    "                 ''.format(average_precision[\"micro\"]))\n",
    "    for i in group:\n",
    "        plt.step(recall[i], precision[i], where='post', label='Precision-recall curve of class {0} (AUPR = {1:0.2f})'\n",
    "                 ''.format(i, average_precision[i]))\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve (Classes {})'.format(group))\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr['micro'], tpr['micro'], label='Micro-average ROC curve (AUC = {0:0.2f})'\n",
    "                 ''.format(roc_auc[\"micro\"]))\n",
    "    for i in group:\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (AUC = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve (Classes {})'.format(group))\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890b37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cbbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
