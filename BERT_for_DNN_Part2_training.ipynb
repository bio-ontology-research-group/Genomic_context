{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c622ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free CPU Memory: 679.07 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_free_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.available / (1024.0 ** 3)  # Convert bytes to gigabytes\n",
    "\n",
    "print(f\"Free CPU Memory: {get_free_memory():.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afee737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"WordLevel_tokenizer_trained_InterPro.json\"\n",
    "tokenizer = tokenizer.from_file(tokenizer_path)\n",
    "tokenizer.enable_truncation(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bef36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242995ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2966, 754, 2545, 196, 9231, 2817, 7418, 2526, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode(\"WP_265490204 WP_206642677 WP_053312998 WP_251959347 WP_000076573 WP_227526754 WP_218401808 WP_106925592\")\n",
    "test.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543a8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/toibazd/Most_frequent_IPs.json\", \"r\") as f:\n",
    "    ips = json.load(f)\n",
    "\n",
    "sorted_dict = sorted(ips.items(), key=lambda x: x[1], reverse=True)\n",
    "most_frequent_ips = [item[0] for item in sorted_dict[:100]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84272ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IPR004090', 'IPR011701', 'IPR002514', 'IPR003719', 'IPR002155', 'IPR005750', 'IPR001001', 'IPR004604', 'IPR011603', 'IPR005252']\n"
     ]
    }
   ],
   "source": [
    "print(most_frequent_ips[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ba9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019270896911621094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a41722bbe64a7cb1167a36348d7412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21791\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data_dict = defaultdict(list)\n",
    "enc = MultiLabelBinarizer()\n",
    "\n",
    "with open(\"/home/toibazd/Prot2IP.tsv\", \"r\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter = \"\\t\")\n",
    "    for row in tqdm(reader):\n",
    "        key = row[0].split(\"prot_\")[1].split(\".\")[0]\n",
    "        iprs = eval(row[1])\n",
    "        \n",
    "\n",
    "        for ip in iprs:\n",
    "            if ip in most_frequent_ips:\n",
    "                data_dict[key].append(ip)\n",
    "\n",
    "one_hot_encoded = enc.fit_transform(data_dict.values())\n",
    "one_hot_encoded_dict = {key: value for key, value in zip(data_dict.keys(), one_hot_encoded)}\n",
    "\n",
    "print(len(one_hot_encoded_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08b6debe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21791"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_encoded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "122c228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21791"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "746c4145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0: Count 2156132\n",
      "Number 1: Count 22968\n",
      "2179100\n"
     ]
    }
   ],
   "source": [
    "# Find unique numbers and their counts\n",
    "unique_numbers, counts = np.unique(one_hot_encoded, return_counts=True)\n",
    "all_count = 0\n",
    "# Print the count of each number\n",
    "for number, count in zip(unique_numbers, counts):\n",
    "    all_count+=count\n",
    "    print(f\"Number {number}: Count {count}\")\n",
    "print(all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efeab11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('BERT_DNN_senteces.json', \"r\") as f:\n",
    "    one_hot_encoded_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deeb72f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_sentences = {key: value for key, value in one_hot_encoded_sentences.items() if value}\n",
    "len(one_hot_encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2219cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = one_hot_encoded_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea88291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b43fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-02 14:33:32,737] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final_context5/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(544998, 256, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 256)\n",
       "    (token_type_embeddings): Embedding(2, 256)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): None\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Check if CUDA is available and choose device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"/home/toibazd/Data/BERT/BERT_context_pretrained_InterPro_final_context5/\"\n",
    "\n",
    "model = BertModel.from_pretrained(model_path).cuda()\n",
    "model.pooler = None\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "978dfa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_encoded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c35dd100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01622772216796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 158,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fc3f06efae41d2bf1d9a2dfaa3b4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128 # Define your batch size\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "\n",
    "    # Convert lists to tensors and move to device\n",
    "    input_ids = torch.tensor(input_ids_list).cuda()\n",
    "    attention_mask = torch.tensor(attention_mask_list).cuda()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 5, :]  # Extract the 20th token's hidden state\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[4]\n",
    "        labels.append(one_hot_encoded_dict[indicator])\n",
    "\n",
    "# Ensure order in embeddings matches order in labels\n",
    "\n",
    "# Now embeddings and labels are stored on the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "620352af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    \n",
    "    neg_counts = [len(embeddings)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "      pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)\n",
    "class_counts = np.array(labels).sum(axis=0)\n",
    "pos_weights = calculate_pos_weights(class_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dda8cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([73., 46., 98., 48., 98., 57., 97., 49., 40., 82., 75., 91., 49., 91.,\n",
       "        79., 95., 90., 69., 97., 48., 95., 78., 87., 35., 92., 93., 64., 98.,\n",
       "        40., 91., 96., 85., 90., 99., 99., 99., 89., 91., 99., 99., 37., 86.,\n",
       "        47., 95., 34., 99., 95., 75., 97., 99., 84., 38., 98., 69., 89., 39.,\n",
       "        98., 38., 99., 90., 46., 96., 99., 78., 56., 93., 73., 88., 95., 90.,\n",
       "        99., 87., 62., 42., 51., 49., 97., 57., 91., 39., 33., 81., 99., 49.,\n",
       "        49., 49., 88., 48., 92., 90., 99., 96., 63., 99., 99., 94., 65., 49.,\n",
       "        47., 97.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cad879a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1476691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7184dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f832c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classification_V0(nn.Module):\n",
    "    def __init__(self, input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob):\n",
    "        super(Classification_V0, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, first_hidden)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(first_hidden, second_hidden)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(second_hidden, last_hidden)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(last_hidden, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 256\n",
    "first_hidden = 128\n",
    "second_hidden = 64\n",
    "last_hidden = 32\n",
    "output_dim = 100\n",
    "dropout_prob = 0.25\n",
    "\n",
    "clf_model = Classification_V0(input_dim, first_hidden, second_hidden, last_hidden, output_dim, dropout_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d9abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "batch_size = 128\n",
    "def data_generator(embeddings, labels, batch_size):\n",
    "    num_samples = len(embeddings)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_embeddings = embeddings[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        yield batch_embeddings, batch_labels\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(clf_model.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.05)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad1b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020462512969970703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20167079902265223\n",
      "Epoch 2/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019705533981323242,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08911329147752085\n",
      "Epoch 3/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019611120223999023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08511070518807728\n",
      "Epoch 4/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01956963539123535,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08364225365720374\n",
      "Epoch 5/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019641399383544922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0828315413976139\n",
      "Epoch 6/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019681215286254883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08209820132373333\n",
      "Epoch 7/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019634008407592773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08174304266366655\n",
      "Epoch 8/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02006220817565918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08134791548556485\n",
      "Epoch 9/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0197904109954834,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08114725811923026\n",
      "Epoch 10/10:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019665956497192383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0806330398320797\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_epochs = 10\n",
    "epoch_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    \n",
    "    # Initialize data generator\n",
    "    generator = data_generator(embeddings, labels, batch_size)\n",
    "    train_loss = 0\n",
    "    # Iterate over batches\n",
    "    for batch_embeddings, batch_labels in tqdm(generator, desc=\"Training Batches\", leave=False):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Convert data to tensors\n",
    "\n",
    "        batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_labels_tensor = torch.tensor(batch_labels, dtype = torch.float32)\n",
    "        batch_labels_tensor = batch_labels_tensor.squeeze()\n",
    "\n",
    "        \n",
    "        outputs = clf_model(batch_embeddings_tensor)\n",
    "\n",
    "        \n",
    "        loss = criterion(outputs, batch_labels_tensor)\n",
    "\n",
    "        \n",
    "        train_loss+=loss.item()\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    epoch_loss.append(train_loss/(len(embeddings)/batch_size))\n",
    "    print(train_loss/(len(embeddings)/batch_size))\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT_DNN_senteces_test.json', \"r\") as f:\n",
    "    test_sentences = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ab316ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = {key: value for key, value in test_sentences.items() if value}\n",
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3e213bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = test_sentences.values()\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a93cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_string = [item for sublist in matching_string for item in sublist]\n",
    "len(matching_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d499e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016407251358032227,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 39,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65123cf5e4340968bd853ee79368d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128 # Define your batch size\n",
    "# model.cuda()\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "# Define your data iterator in batches\n",
    "for i in tqdm(range(0, len(matching_string), batch_size)):\n",
    "    batch_sentences = matching_string[i:i+batch_size]\n",
    "\n",
    "    batch_inputs = tokenizer.encode_batch(batch_sentences)\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    for encoding in batch_inputs:\n",
    "        input_ids_list.append(encoding.ids)\n",
    "        attention_mask_list.append(encoding.attention_mask)\n",
    "    # Convert lists to tensors and move to device\n",
    "    try:\n",
    "        input_ids = torch.tensor(input_ids_list)\n",
    "    except:\n",
    "        for ins in input_ids_list:\n",
    "            if len(ins)!=42:\n",
    "                print(len(ins))\n",
    "                print(ins)\n",
    "    attention_mask = torch.tensor(attention_mask_list)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    relevant_hidden_states = hidden_states[:, 5, :]  # Extract the 20th token's hidden state\n",
    "    \n",
    "    for j in range(len(batch_sentences)):\n",
    "        # Move embeddings to CPU\n",
    "        test_embeddings.append(relevant_hidden_states[j].cpu())\n",
    "        indicator = batch_sentences[j].split()[4]\n",
    "        test_labels.append(one_hot_encoded_dict[indicator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b5d975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6194248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_V0(\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc4): Linear(in_features=32, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9642349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021244525909423828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluation Batches",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = data_generator(test_embeddings, test_labels, batch_size)\n",
    "\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "for batch_embeddings, batch_labels in tqdm(generator, desc=\"Evaluation Batches\", leave=False):\n",
    "    batch_embeddings_tensor = torch.stack(batch_embeddings)\n",
    "    batch_labels = np.array(batch_labels)\n",
    "    \n",
    "    logits = clf_model(batch_embeddings_tensor)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "    thresholded_predictions = (predictions > 0.04).float()\n",
    "    all_predictions.append(thresholded_predictions.detach().numpy())\n",
    "    all_labels.append(batch_labels)\n",
    "    all_probs.append(predictions.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a8783cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd77c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41649db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100)\n"
     ]
    }
   ],
   "source": [
    "print(all_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7cc0ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate predictions and labels across all batches\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_probs = np.concatenate(all_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bed25c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP-centric AUC score:  \n",
      "0 :  0.42179008547008545\n",
      "1 :  0.4537607368147406\n",
      "2 :  0.5790000000000001\n",
      "3 :  0.5947741273100615\n",
      "4 :  0.35792244897959186\n",
      "5 :  0.5604019567679591\n",
      "6 :  0.4583938568472804\n",
      "7 :  0.703319587628866\n",
      "8 :  0.9945880897887127\n",
      "9 :  0.3007856378822985\n",
      "10 :  0.5466639095671353\n",
      "11 :  0.6230363139336159\n",
      "12 :  0.4658041237113402\n",
      "13 :  0.3549263755308207\n",
      "14 :  0.3866467969709374\n",
      "15 :  0.40668119099491656\n",
      "16 :  0.46265744259823477\n",
      "17 :  0.8476212954763983\n",
      "18 :  0.4647634823826376\n",
      "19 :  0.36925360824742265\n",
      "20 :  0.4705877983099638\n",
      "21 :  0.6548520506353686\n",
      "22 :  0.823418029882478\n",
      "23 :  0.8503857248590894\n",
      "24 :  0.4736519658119658\n",
      "25 :  0.5287428571428572\n",
      "26 :  0.6293858368848153\n",
      "27 :  0.271020899889208\n",
      "28 :  0.674440261001856\n",
      "29 :  0.3668726638816472\n",
      "30 :  0.2912506051803438\n",
      "31 :  0.560712096444626\n",
      "32 :  0.6747356262833675\n",
      "33 :  0.3291183673469388\n",
      "34 :  0.33832244897959185\n",
      "35 :  0.7635387755102041\n",
      "36 :  0.4683348742640555\n",
      "37 :  0.47036810233380966\n",
      "38 :  0.5118163265306123\n",
      "39 :  0.521526530612245\n",
      "40 :  0.9718206717883582\n",
      "41 :  0.20163903321851828\n",
      "42 :  0.7660223742962532\n",
      "43 :  0.7499788687404787\n",
      "44 :  0.9361961592347209\n",
      "45 :  0.5211836734693878\n",
      "46 :  0.2249219160488061\n",
      "47 :  0.8331053373083261\n",
      "48 :  0.13355666822760948\n",
      "49 :  0.4567061224489796\n",
      "50 :  0.5061368107294788\n",
      "51 :  0.9884376396536835\n",
      "52 :  0.40688575899843504\n",
      "53 :  0.9192216616176889\n",
      "54 :  0.7360032529379599\n",
      "55 :  0.9868087334883748\n",
      "56 :  0.23484860382573736\n",
      "57 :  0.9787520125572029\n",
      "58 :  0.7364653061224489\n",
      "59 :  0.32217910312273057\n",
      "60 :  0.5478396494772291\n",
      "61 :  0.38236294722012093\n",
      "62 :  0.3179142857142857\n",
      "63 :  0.5839747166189022\n",
      "64 :  0.6671051546391753\n",
      "65 :  0.3150938775510205\n",
      "66 :  0.7878211644291773\n",
      "67 :  0.03042448979591838\n",
      "68 :  0.4447351285538701\n",
      "69 :  0.3575306122448979\n",
      "70 :  0.3929918367346939\n",
      "71 :  0.14225306122448977\n",
      "72 :  0.6235859119644569\n",
      "73 :  0.9885897384108444\n",
      "74 :  0.7083408815010547\n",
      "75 :  0.6011634310890817\n",
      "76 :  0.3492163265306123\n",
      "77 :  0.873689101084787\n",
      "78 :  0.8279876160990712\n",
      "79 :  0.9686652329749104\n",
      "80 :  0.5743080836738987\n",
      "81 :  0.43813981872990215\n",
      "82 :  0.4978591745340111\n",
      "83 :  0.8252847516560163\n",
      "84 :  0.6986103092783504\n",
      "85 :  0.5347319587628866\n",
      "86 :  0.324299877125784\n",
      "87 :  0.8655453055620405\n",
      "88 :  0.4960676248454066\n",
      "89 :  0.6074794872396716\n",
      "90 :  nan\n",
      "91 :  0.4201747893866624\n",
      "92 :  0.660807897212576\n",
      "93 :  0.08244489795918364\n",
      "94 :  0.4718979591836735\n",
      "95 :  0.4625828438609165\n",
      "96 :  0.5491637194223401\n",
      "97 :  0.8133257731958763\n",
      "98 :  0.7632550675412493\n",
      "99 :  0.32399890576055423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toibazd/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1146: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "auc_scores = []\n",
    "\n",
    "for i in range(all_labels.shape[1]):  # Iterate over each column\n",
    "    y = all_labels[:, i]\n",
    "    pred_y = all_probs[:, i]\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred_y)\n",
    "    auc_score = metrics.auc(fpr, tpr)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "print(\"IP-centric AUC score:  \")\n",
    "for idx, score in enumerate(auc_scores):\n",
    "    print(idx,\": \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6895d54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Increase the size of the plot\n",
    "plt.hist(auc_scores, bins=20, color='b', alpha=0.7)  # Plot histogram with 10 bins, blue color, and transparency\n",
    "plt.xlabel('AUC scores')  # Label x-axis\n",
    "plt.ylabel('Frequency')  # Label y-axis\n",
    "plt.title('Histogram of AUC Score distribution')  # Add a title\n",
    "plt.grid(True)  # Add grid lines\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3a17e99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950, 100)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "541ab895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "cl_report = multilabel_confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Classification report:\")\n",
    "print(len(cl_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5563973c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4790,   85],\n",
       "       [  75,    0]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_report[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6bb7d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_predictions, zero_division=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "93ae8c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  85.,  436.,  287.,  287.,  272.,  206.,  197.,  551.,  287.,\n",
       "        197.,  188.,  287.,  321.,    0.,  287.,    0.,  325.,  197.,\n",
       "        287.,  439.,    0.,  287.,    0.,  287.,  272.,    0.,  378.,\n",
       "        272.,  436.,  129.,  287.,  188.,  272.,  197.,  197.,  287.,\n",
       "        206.,  287.,  197.,    0.,  287.,    0.,  439.,    0.,  287.,\n",
       "        287.,  188.,    0.,   49.,    0.,  188.,  197.,  272.,    0.,\n",
       "          0.,  197.,    0.,  197.,   63.,  188.,  378.,  206.,  287.,\n",
       "        129.,  436.,  206.,  378.,  197.,    0.,    0.,  206.,  211.,\n",
       "        378.,  181.,  369.,  288.,  287.,  287.,    0.,  287., 1065.,\n",
       "        272.,  263.,  466.,  378., 1061.,  197.,  439.,  287.,   76.,\n",
       "        188.,    0.,  511.,  287.,  197.,  167.,  319.,  631.,  632.,\n",
       "        188.], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "924972e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        75\n",
      "           1       0.00      0.00      0.00       117\n",
      "           2       0.00      0.00      0.00        50\n",
      "           3       0.00      0.00      0.00        80\n",
      "           4       0.00      0.00      0.00        50\n",
      "           5       0.00      0.00      0.00        68\n",
      "           6       0.00      0.00      0.00        53\n",
      "           7       0.00      0.00      0.00       100\n",
      "           8       1.00      0.99      1.00       289\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.00      0.00      0.00       114\n",
      "          11       0.00      0.00      0.00        51\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13        nan      0.00      0.00        51\n",
      "          14       0.00      0.00      0.00        64\n",
      "          15        nan      0.00      0.00        54\n",
      "          16       0.00      0.00      0.00        52\n",
      "          17       0.00      0.00      0.00       131\n",
      "          18       0.00      0.00      0.00        57\n",
      "          19       0.00      0.00      0.00       100\n",
      "          20        nan      0.00      0.00        55\n",
      "          21       0.00      0.00      0.00       137\n",
      "          22        nan      0.00      0.00       112\n",
      "          23       1.00      0.78      0.88       368\n",
      "          24       0.00      0.00      0.00        75\n",
      "          25        nan      0.00      0.00        50\n",
      "          26       0.09      0.62      0.16        56\n",
      "          27       0.00      0.00      0.00        57\n",
      "          28       0.08      0.22      0.12       161\n",
      "          29       0.00      0.00      0.00        52\n",
      "          30       0.00      0.00      0.00        54\n",
      "          31       0.00      0.00      0.00        56\n",
      "          32       0.00      0.00      0.00        80\n",
      "          33       0.00      0.00      0.00        50\n",
      "          34       0.00      0.00      0.00        50\n",
      "          35       0.00      0.00      0.00        50\n",
      "          36       0.00      0.00      0.00        51\n",
      "          37       0.00      0.00      0.00        51\n",
      "          38       0.00      0.00      0.00        50\n",
      "          39        nan      0.00      0.00        50\n",
      "          40       1.00      0.93      0.96       308\n",
      "          41        nan      0.00      0.00        56\n",
      "          42       0.00      0.00      0.00       102\n",
      "          43        nan      0.00      0.00       105\n",
      "          44       1.00      0.85      0.92       338\n",
      "          45       0.00      0.00      0.00        50\n",
      "          46       0.00      0.00      0.00        56\n",
      "          47        nan      0.00      0.00       132\n",
      "          48       0.00      0.00      0.00        51\n",
      "          49        nan      0.00      0.00        50\n",
      "          50       0.00      0.00      0.00        79\n",
      "          51       1.00      0.64      0.78       307\n",
      "          52       0.00      0.00      0.00        51\n",
      "          53        nan      0.00      0.00       117\n",
      "          54        nan      0.00      0.00       103\n",
      "          55       1.00      0.66      0.80       298\n",
      "          56        nan      0.00      0.00        52\n",
      "          57       1.00      0.66      0.80       298\n",
      "          58       0.00      0.00      0.00        50\n",
      "          59       0.00      0.00      0.00        54\n",
      "          60       0.00      0.00      0.00       109\n",
      "          61       0.00      0.00      0.00        51\n",
      "          62       0.00      0.00      0.00        50\n",
      "          63       0.00      0.00      0.00        59\n",
      "          64       0.00      0.00      0.00       100\n",
      "          65       0.00      0.00      0.00        50\n",
      "          66       0.00      0.00      0.00        94\n",
      "          67       0.00      0.00      0.00        50\n",
      "          68        nan      0.00      0.00        53\n",
      "          69        nan      0.00      0.00        50\n",
      "          70       0.00      0.00      0.00        50\n",
      "          71       0.00      0.00      0.00        50\n",
      "          72       0.09      0.42      0.15        84\n",
      "          73       1.00      0.61      0.76       298\n",
      "          74       0.00      0.00      0.00        99\n",
      "          75       0.00      0.00      0.00       108\n",
      "          76       0.00      0.00      0.00        50\n",
      "          77       0.00      0.00      0.00        67\n",
      "          78        nan      0.00      0.00       105\n",
      "          79       1.00      0.96      0.98       300\n",
      "          80       0.10      0.38      0.15       268\n",
      "          81       0.00      0.00      0.00        61\n",
      "          82       0.00      0.00      0.00        54\n",
      "          83       0.00      0.00      0.00        79\n",
      "          84       0.00      0.00      0.00       100\n",
      "          85       0.02      0.24      0.04       100\n",
      "          86       0.00      0.00      0.00        51\n",
      "          87       0.00      0.00      0.00        89\n",
      "          88       0.00      0.00      0.00        51\n",
      "          89       0.00      0.00      0.00        61\n",
      "          90       0.00       nan      0.00         0\n",
      "          91        nan      0.00      0.00        65\n",
      "          92       0.00      0.00      0.00        77\n",
      "          93       0.00      0.00      0.00        50\n",
      "          94       0.00      0.00      0.00        50\n",
      "          95       0.00      0.00      0.00        52\n",
      "          96       0.00      0.00      0.00        78\n",
      "          97       0.00      0.01      0.00       100\n",
      "          98       0.02      0.10      0.03       106\n",
      "          99       0.00      0.00      0.00        53\n",
      "\n",
      "   micro avg       0.10      0.26      0.14      9461\n",
      "   macro avg       0.11      0.09      0.09      9461\n",
      "weighted avg       0.35      0.26      0.27      9461\n",
      " samples avg       0.07      0.06      0.02      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21f752be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IPR000212'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.classes_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e4706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
